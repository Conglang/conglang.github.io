<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="论文，StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation, Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo">
<meta property="og:type" content="article">
<meta property="og:title" content="论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation">
<meta property="og:url" content="http://conglang.github.io/2017/12/20/essay-stargan/index.html">
<meta property="og:site_name" content="A Stellar Hiker">
<meta property="og:description" content="论文，StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation, Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo">
<meta property="og:image" content="http://conglang.github.io/img/4586E806-7AA7-496B-9DAB-8EE7DFF142AC.png">
<meta property="og:image" content="http://conglang.github.io/img/B65F153F-68A0-4F85-B533-546A25787653.png">
<meta property="og:image" content="http://conglang.github.io/img/2E6153A2-31F7-4E8A-8AD6-975CE7DC3063.png">
<meta property="og:image" content="http://conglang.github.io/img/D77BDBCF-343B-4A87-949B-E884308893BF.png">
<meta property="og:image" content="http://conglang.github.io/img/909D3764-C17F-4341-A3B7-8922B0F95916.png">
<meta property="og:image" content="http://conglang.github.io/img/86FDECC4-B504-446C-B214-EACF0B9FD147.png">
<meta property="og:image" content="http://conglang.github.io/img/B8950B66-4ABD-4A30-AF7C-2C31953DB5A1.png">
<meta property="og:image" content="http://conglang.github.io/img/D1027F0F-8F21-45C9-90E2-28B470AB63F3.png">
<meta property="og:image" content="http://conglang.github.io/img/8F01C3BE-E2A3-47AA-A657-290DE9D2B4A8.png">
<meta property="og:image" content="http://conglang.github.io/img/27AEA299-D801-4EB0-AFC7-D98C4C12CDEE.png">
<meta property="og:image" content="http://conglang.github.io/img/E440E222-05A6-462B-9FE3-EBAC2B520947.png">
<meta property="og:image" content="http://conglang.github.io/img/23A4B100-DACF-4EE6-BCD7-5DD4EF8E9697.png">
<meta property="og:image" content="http://conglang.github.io/img/97646578-59FD-48EB-B877-406F0C9E4158.png">
<meta property="og:image" content="http://conglang.github.io/img/10DD9E8B-2F68-4561-B41A-AC9FC1E429FB.png">
<meta property="og:image" content="http://conglang.github.io/img/5626F257-13C9-4DBD-A80A-05FF3F37F603.png">
<meta property="og:image" content="http://conglang.github.io/img/6EA05734-E694-48A8-B120-5AD90A01EA71.png">
<meta property="og:image" content="http://conglang.github.io/img/FDE27BC0-DF99-4700-89F6-E4FE0EC6E018.png">
<meta property="og:updated_time" content="2018-07-31T15:04:59.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation">
<meta name="twitter:description" content="论文，StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation, Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo">
<meta name="twitter:image" content="http://conglang.github.io/img/4586E806-7AA7-496B-9DAB-8EE7DFF142AC.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/astro.png">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/astro.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/astro.png">
          
        
    
    <!-- title -->
    <title>论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
  	<link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">
</head>

<body class="max-width mx-auto px3 ltr">    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/archives/">博文</a></li>
         
          <li><a href="/categories/">分类</a></li>
         
          <li><a href="/tags/">标签</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/02/01/ml-series/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2017/12/09/essay-dynamic-routing-between-capsules/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://conglang.github.io/2017/12/20/essay-stargan/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://conglang.github.io/2017/12/20/essay-stargan/&text=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://conglang.github.io/2017/12/20/essay-stargan/&is_video=false&description=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation&body=Check out this article: http://conglang.github.io/2017/12/20/essay-stargan/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://conglang.github.io/2017/12/20/essay-stargan/&name=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text"> Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#related-work"><span class="toc-number">2.</span> <span class="toc-text"> Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#star-generative-adversarial-networks"><span class="toc-number">3.</span> <span class="toc-text"> Star Generative Adversarial Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-domain-image-to-image-translation"><span class="toc-number">3.1.</span> <span class="toc-text"> Multi-Domain Image-to-Image Translation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training-with-multiple-datasets"><span class="toc-number">3.2.</span> <span class="toc-text"> Training with Multiple Datasets</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#implementation"><span class="toc-number">4.</span> <span class="toc-text"> Implementation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#experiments"><span class="toc-number">5.</span> <span class="toc-text"> Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#baseline-models"><span class="toc-number">5.1.</span> <span class="toc-text"> Baseline Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#datasets"><span class="toc-number">5.2.</span> <span class="toc-text"> Datasets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training"><span class="toc-number">5.3.</span> <span class="toc-text"> Training</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index my4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">A Stellar Hiker</span>
      </span>
      
    <div class="postdate">
        <time datetime="2017-12-20T00:54:00.000Z" itemprop="datePublished">2017-12-20</time>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tag-link" href="/tags/Essay/">Essay</a>, <a class="tag-link" href="/tags/GAN/">GAN</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation<br>
Image-to-image translation for multiple domains using only a single model.<br>
<img src="/img/4586E806-7AA7-496B-9DAB-8EE7DFF142AC.png" alt="Image Loading"></p>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<p>The task of image-to-image translation is to change a particular aspect of a given image to another. 比如上图改变人物面部表情，自从generative adversarial networks(GANs)出现之后有了很大进展。</p>
<p>Attribute, meaningful feature inherent in an image比如发色。<br>
Attribute value, a particular value of an attribute比如金发。<br>
Domain, a set of images sharing the same attribute value.比如所有女士照片是一个domain，男士照片是另一个。</p>
<p>一些有labeled attributes的数据集。</p>
<ul>
<li>CelebA, 40 labels related to facial attributes, such as hair color, gender, age.</li>
<li>RaFD, 8 labels for facial expressions, such as happy, angry, sad.</li>
</ul>
<p>Cross-domain model对multi-domain image-to-image translation效率和效果都不太好。k的domain需要训练k(k-1)个generator。每个generator只能用到其对应2个domain的data。且不能使用多个数据集，因为其会是partially labeled。<br>
<img src="/img/B65F153F-68A0-4F85-B533-546A25787653.png" alt="Image Loading"><br>
StarGAN克服了这些困难。</p>
<ul>
<li>one single generator and a discriminator</li>
<li>multi-domain image translation between multiple datasets by utilizing a mask vector method that enables StarGAN to control all available domain labels.</li>
</ul>
<h2 id="related-work"><a class="markdownIt-Anchor" href="#related-work"></a> Related Work</h2>
<ul>
<li>Generative Adversarial Network.<br>
在computer vision领域用于image generation, image translation, super-resolution imaging, face image synthesis.<br>
典型结构包括两个module，discriminator和generator。Discriminator learns to distinguish between real and fake samples, while the generator learns to generate fake samples that are indistinguishable from real samples.<br>
StarGAN用到其adversarial loss用来使生成图片更真实。</li>
<li>Conditional GANs<br>
Prior studies have provided both the discriminator and generator with class information in order to generate samples conditioned on the class.<br>
应用场景如generating particular images highly relevant to a given text description, domain transfer, super-resolution imaging, photo editing.</li>
<li>Image-to-Image Translation<br>
Pix2pix, cGANs. It combines an adversarial loss with a L1 loss, thus requires paired data samples.<br>
UNIT combines variational autoencoders (VAEs) with CoGAN, a GAN framework where two generators share weights to learn the joint distribution of images in cross domains.<br>
CycleGAN and DiscoGAN preserve key attributes between the input and the translated image by utilizing a cycle consistency loss.<br>
然而这些都一次只能学习两个domain的关系。</li>
</ul>
<h2 id="star-generative-adversarial-networks"><a class="markdownIt-Anchor" href="#star-generative-adversarial-networks"></a> Star Generative Adversarial Networks</h2>
<h3 id="multi-domain-image-to-image-translation"><a class="markdownIt-Anchor" href="#multi-domain-image-to-image-translation"></a> Multi-Domain Image-to-Image Translation</h3>
<p><img src="/img/2E6153A2-31F7-4E8A-8AD6-975CE7DC3063.png" alt="Image Loading"></p>
<p><strong>Adversarial Loss</strong><br>
图片真不真。<br>
To make the generated images indistinguishable from real images.<br>
<img src="/img/D77BDBCF-343B-4A87-949B-E884308893BF.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span></span></span></span> generates an image <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">G(x, c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mathit">c</span><span class="mclose">)</span></span></span></span> conditioned on both the input image <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span> and the target domain label <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">c</span></span></span></span>.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span> tries to distinguish between real and fake images.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mrow><mi>s</mi><mi>r</mi><mi>c</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">D_{src}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">s</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">c</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> is a probability distribution over sources given by <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span>.<br>
The generator <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span></span></span></span> tries to minimize this objective, while the discriminator <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span> tries to maximize it.</p>
<p><strong>Domain Classification Loss</strong><br>
标签对不对。</p>
<ol>
<li>A domain classification loss of real images used to optimize D.<br>
<img src="/img/909D3764-C17F-4341-A3B7-8922B0F95916.png" alt="Image Loading"><br>
D_{cls}(c’|x) represents a probability distribution over domain labels computed by <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span>. By minimizing this objective, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span> learns to classify a real image <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span> to its corresponding original domain c’.<br>
We assume that the input image and domain label pair (x, c’) is given by the training data.</li>
<li>A domain classification loss of fake images used to optimize G.<br>
<img src="/img/86FDECC4-B504-446C-B214-EACF0B9FD147.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span></span></span></span> tries to minimize this objective to generate images that can be classified as the target domain <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">c</span></span></span></span>.</li>
</ol>
<p><strong>Reconstruction Loss</strong><br>
保证只更改domain-related part。<br>
有前两个loss，G is trained to generate images that are realistic and classified to its correct target domain.<br>
然而，这两个不能保证translated images preserve the content of its input images while changing only the domain-related part of the inputs.<br>
Apply a cycle consistency loss to the generator,<br>
<img src="/img/B8950B66-4ABD-4A30-AF7C-2C31953DB5A1.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span></span></span></span> takes in the translated image <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">G(x,c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mathit">c</span><span class="mclose">)</span></span></span></span> and the original domain label c’ as input and tries to reconstruct the original image <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span>.<br>
Adopt L1 norm as reconstruction loss.</p>
<p><strong>Full Objective</strong><br>
The objective functions to optimize <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">G</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span></span> is:<br>
<img src="/img/D1027F0F-8F21-45C9-90E2-28B470AB63F3.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span>是hyper-parameter来调节各loss的比例。作者用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\lambda_{cls} = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">λ</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">c</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">s</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>r</mi><mi>e</mi><mi>c</mi></mrow></msub><mo>=</mo><mn>1</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda_{rec} = 10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">λ</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">c</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">0</span></span></span></span>。</p>
<h3 id="training-with-multiple-datasets"><a class="markdownIt-Anchor" href="#training-with-multiple-datasets"></a> Training with Multiple Datasets</h3>
<p>An issue when learning from multiple datasets, however, is that the label information is only partially known to each dataset. A有的B没有，B有的A没有。<br>
<img src="/img/8F01C3BE-E2A3-47AA-A657-290DE9D2B4A8.png" alt="Image Loading"></p>
<p><strong>Mask Vector</strong><br>
allows StarGAN to ignore unspecified labels and focus on the explicitly known label provided by a particular dataset.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">m</span></span></span></span>, n-dimensional one-hot vector, n is the number of datasets.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>c</mi><mtext> </mtext></msup></mrow><annotation encoding="application/x-tex">c^~</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mspace"> </span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>, unified version of the label as a vector, c^~ = [c_1, …, c_n, m]. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mi mathvariant="normal">.</mi><mo>]</mo></mrow><annotation encoding="application/x-tex">[.]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">[</span><span class="mord mathrm">.</span><span class="mclose">]</span></span></span></span> refers to concatenation, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> represents a vector for the labels of the i-th dataset. For the remaining n-1 unknown labels we simply assign zero values.</p>
<p><strong>Training Strategy</strong><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>c</mi><mtext> </mtext></msup></mrow><annotation encoding="application/x-tex">c^~</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">c</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mspace"> </span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>作为generator的input。</p>
<h2 id="implementation"><a class="markdownIt-Anchor" href="#implementation"></a> Implementation</h2>
<p><strong>Improved GAN Training</strong><br>
To stabilize the training process and generate higher quality images, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>a</mi><mi>d</mi><mi>v</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{adv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">L</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">a</span><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.03588em;">v</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>改用Wasserstein GAN objective with gradient penalty.<br>
<img src="/img/27AEA299-D801-4EB0-AFC7-D98C4C12CDEE.png" alt="Image Loading"><br>
Where <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord mathit">x</span></span><span style="top:0em;margin-left:0.05556em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body"><span>^</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> is sampled uniformly along a straight line between a pair of real and a generated images . We use <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>g</mi><mi>p</mi></mrow></msub><mo>=</mo><mn>1</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda_{gp} = 10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">λ</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">p</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">0</span></span></span></span> for all experiments.</p>
<p><strong>Network Architecture</strong><br>
Generator network: two convolution layers with the stride size of two for downsampling, six residual blocks, and two transposed convolution layers with the stride size of two for upsampling. Instance normalization.<br>
Discriminator network: PatchGANs, no normalization.<br>
<img src="/img/E440E222-05A6-462B-9FE3-EBAC2B520947.png" alt="Image Loading"><br>
<img src="/img/23A4B100-DACF-4EE6-BCD7-5DD4EF8E9697.png" alt="Image Loading"></p>
<h2 id="experiments"><a class="markdownIt-Anchor" href="#experiments"></a> Experiments</h2>
<p><img src="/img/97646578-59FD-48EB-B877-406F0C9E4158.png" alt="Image Loading"><br>
<img src="/img/10DD9E8B-2F68-4561-B41A-AC9FC1E429FB.png" alt="Image Loading"><br>
<img src="/img/5626F257-13C9-4DBD-A80A-05FF3F37F603.png" alt="Image Loading"></p>
<h3 id="baseline-models"><a class="markdownIt-Anchor" href="#baseline-models"></a> Baseline Models</h3>
<ul>
<li><strong>DIAT</strong> uses an adversarial loss to learn the mapping from <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">x \in X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.72243em;vertical-align:-0.0391em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span><span class="mrel">∈</span><span class="mord mathit" style="margin-right:0.07847em;">X</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>∈</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">y \in Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">∈</span><span class="mord mathit" style="margin-right:0.22222em;">Y</span></span></span></span> , where x and y are face images in two different domains X and Y , respectively. This method has a regularization term on the mapping as ||x − F (G(x))||_1 to preserve identity features of the source image, where F is a feature extractor pretrained on a face recognition task.</li>
<li><strong>CycleGAN</strong> also uses an adversarial loss to learn the map- ping between two different domains X and Y . This method regularizes the mapping via cycle consistency losses, ||x−(G_{YX}(G_{XY}(x)))||_1 and ||y−(G_{XY}(G_{YX}(y)))||_1. This method requires two generators and discriminators for each pair of two different domains.</li>
<li><strong>IcGAN</strong> combines an encoder with a cGAN model. cGAN learns the mapping $G : {z, c} \rightarrow x $that generates an image <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span> conditioned on both the random noise <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.04398em;">z</span></span></span></span> and the conditional representation c. In addition, IcGAN learns the inverse mappings <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>z</mi></msub><mo>:</mo><mi>x</mi><mo>→</mo><mi>z</mi></mrow><annotation encoding="application/x-tex">E_z :x \rightarrow z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.04398em;">z</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">:</span><span class="mord mathit">x</span><span class="mrel">→</span><span class="mord mathit" style="margin-right:0.04398em;">z</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mi>c</mi></msub><mo>:</mo><mi>x</mi><mo>→</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">E_c :x \rightarrow c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">c</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">:</span><span class="mord mathit">x</span><span class="mrel">→</span><span class="mord mathit">c</span></span></span></span>. This allows to synthesize images conditioned on arbitrary conditional representation.</li>
</ul>
<h3 id="datasets"><a class="markdownIt-Anchor" href="#datasets"></a> Datasets</h3>
<ul>
<li><strong>CelebA</strong>. 202,599 face images of celebrities, each annotated with 40 binary attributes. We crop the initial 178 × 218 size images to 178 × 178, then resize them as 128 × 128. We randomly select 2,000 images as test set and use all remaining images for training data. We construct seven domains using the following attributes: hair color (black, blond, brown), gender (male/female), and age (young/old).</li>
<li><strong>RaFD</strong>. 4,824 images collected from 67 participants. Each participant makes eight facial expressions in three different gaze directions, which are captured from three different angles. We crop the images to 256 × 256, where the faces are centered, and then resize them to 128 × 128.</li>
</ul>
<h3 id="training"><a class="markdownIt-Anchor" href="#training"></a> Training</h3>
<p>Adam<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">\beta_1 = 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>9</mn><mn>9</mn></mrow><annotation encoding="application/x-tex">\beta_2 = 0.999</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">9</span><span class="mord mathrm">9</span><span class="mord mathrm">9</span></span></span></span>.<br>
For data augmentation we flip the images horizontally with a probability of 0.5.<br>
One generator update after five discriminator updates as in Reconstruction Loss.<br>
The batch size is set to 16 for all experiments.<br>
For experiments on CelebA, we train all models with a learning rate of 0.0001 for the first 10 epochs and linearly decay the learn- ing rate to 0 over the next 10 epochs. To compensate for the lack of data, when training with RaFD we train all models for 100 epochs with a learning rate of 0.0001 and apply the same decaying strategy over the next 100 epochs.</p>
<p><img src="/img/6EA05734-E694-48A8-B120-5AD90A01EA71.png" alt="Image Loading"><br>
<img src="/img/FDE27BC0-DF99-4700-89F6-E4FE0EC6E018.png" alt="Image Loading"></p>
<p>Ref:<br>
[1] <a href="https://arxiv.org/abs/1711.09020" target="_blank" rel="external">https://arxiv.org/abs/1711.09020</a><br>
[2] <a href="https://github.com/yunjey/StarGAN" target="_blank" rel="external">https://github.com/yunjey/StarGAN</a></p>

  </div>
</article>



    </div>
    
      <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/archives/">博文</a></li>
         
          <li><a href="/categories/">分类</a></li>
         
          <li><a href="/tags/">标签</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text"> Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#related-work"><span class="toc-number">2.</span> <span class="toc-text"> Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#star-generative-adversarial-networks"><span class="toc-number">3.</span> <span class="toc-text"> Star Generative Adversarial Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-domain-image-to-image-translation"><span class="toc-number">3.1.</span> <span class="toc-text"> Multi-Domain Image-to-Image Translation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training-with-multiple-datasets"><span class="toc-number">3.2.</span> <span class="toc-text"> Training with Multiple Datasets</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#implementation"><span class="toc-number">4.</span> <span class="toc-text"> Implementation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#experiments"><span class="toc-number">5.</span> <span class="toc-text"> Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#baseline-models"><span class="toc-number">5.1.</span> <span class="toc-text"> Baseline Models</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#datasets"><span class="toc-number">5.2.</span> <span class="toc-text"> Datasets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training"><span class="toc-number">5.3.</span> <span class="toc-text"> Training</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://conglang.github.io/2017/12/20/essay-stargan/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://conglang.github.io/2017/12/20/essay-stargan/&text=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://conglang.github.io/2017/12/20/essay-stargan/&is_video=false&description=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation&body=Check out this article: http://conglang.github.io/2017/12/20/essay-stargan/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://conglang.github.io/2017/12/20/essay-stargan/&title=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://conglang.github.io/2017/12/20/essay-stargan/&name=论文 StarGAN - Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

    
    <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2018 聪
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/archives/">博文</a></li>
         
          <li><a href="/categories/">分类</a></li>
         
          <li><a href="/tags/">标签</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>

<!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

<!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-74786593-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?4e074986ce7bd4c6c94338ce1a49c4be";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->



