<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Coursera上Machine Learning课程的笔记。介绍了Supervised Learning, Unsupervised Learning, Special applications/special topics, Advice on building a machine learning system等内容。">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning 课程笔记">
<meta property="og:url" content="http://conglang.github.io/2015/07/15/note-machine-learning-coursera/index.html">
<meta property="og:site_name" content="A Stellar Hiker">
<meta property="og:description" content="Coursera上Machine Learning课程的笔记。介绍了Supervised Learning, Unsupervised Learning, Special applications/special topics, Advice on building a machine learning system等内容。">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_introduction.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_supervised_learning_housing_price_prediction.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_supervised_learning_breast_cancer.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_training_set_of_housing_prices.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_housing_price_process.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_cost_function_eg.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_cost_function_intuition_i.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_j_3d.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_cost_function_contour1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_cost_function_contour4.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_alpha.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_for_linear_regression_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_for_linear_regression_algorithm1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_for_linear_regression_algorithm2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multiple_features_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_multivariable_formula.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_descent_multi_formula.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_polynomial_regression_house_price.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_normal_equation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_normal_equation_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gd_ne_compare.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_sigmoid_function_line.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_sigmoid_function_line.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_decision_boundary1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_non_linear_decision_boundaries.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_cost_function.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_cost_function_formula.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_cost_function_y1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_cost_function_y0.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_cost_function_review.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_linear_regression_j.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_cost_function_changed.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_gradient_descent1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_gradient_descent2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_optimization_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_optimization_algorithm_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_optimization_algorithm_implement.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multiclass_classification.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multiclass_classification_onevsall.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_one_vs_all.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_overfitting_linear_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_overfitting_logistic_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularization_intuition.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularization_formular.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_linear_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_linear_regression_gradient_descent.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_linear_regression_normal_equation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_linear_regression_non_invertibility.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_logistic_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_logistic_regression_gradient_descent.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_regularized_logistic_regression_advanced_optimization.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_non_linear_classification.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_nn_computervision_1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_nn_computervision_2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_nn_computervision_3.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_sensor_representations_in_the_brain.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neuron_in_the_brain1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neuron_in_the_brain2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neuron_model_logistic_unit.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_network.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_network_formula.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_forward_propagation_vectorized_implementation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_network_learning_its_own_features.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_other_network_architectures.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_non_linear_classification_example_xor_xnor.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_simple_example_AND.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_example_or_function.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_negation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_putting_it_together.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_network_intuition.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_handwriting_digit_classification.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multiple_output_units_one_vs_all.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multiple_output_units_one_vs_all1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_network_classification.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_network_cost_function.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_computation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_computation1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_backpropagation_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_backpropagation_algorithm1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_nn_forward_propagation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_what_is_backpropagation_doing.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_what_is_backpropagation_doing1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_advanced_optimization.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_learning_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_numerical_estimation_of_gradients.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_parameter_vector.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_parameter_vector_implement.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gradient_checking.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_zero_initialization.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_random_initialization.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_nn_pick_network_arch.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_training_a_neural_network1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_training_a_neural_network2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_autonomous_driving.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_debugging_a_learning_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_training_testing_procedure_for_linear_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_training_testing_procedure_for_logistic_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_model_selection.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_evaluating_your_hypothesis.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_train_validation_test.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_model_selection_better.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_bias_variance1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_bias_variance2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_diagnosing_bias_vs_variance.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_linear_regression_with_regularization.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_the_regularization_parameter_lambda.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_the_regularization_parameter_lambda1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_bias_variance_as_a_function_of_the_regularization_parameter_lambda.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_learning_curves.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_high_bias.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_high_variance.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_neural_networks_and_overfitting.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_building_a_spam_classifier_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_building_a_spam_classifier_method.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_error_analysis.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_cancer_classification_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_precision_recall.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_trading_off_precision_and_recall.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_f1_score.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_designing_a_high_accuracy_learning_system.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_large_data_rationale.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_large_data_rationale1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_alternative_view_of_logistic_regression1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_alternative_view_of_logistic_regression2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_support_vector_machine.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_hypothesis.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_support_vector_machine_revisited.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_decision_boundary.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_decision_boundary_linearly_separable_case.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_large_margin_classifiers_in_presence_of_outliers.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_vector_inner_product.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_decision_boundary_math.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_decision_boundary_math1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_non_linear_decision_boundary.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_kernal.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_kernals_and_similarity.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_kernal_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_kernal_example1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_the_landmarks.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_with_kernels.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_with_kernels1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_svm_parameters.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_using_an_svm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_kernel_functions.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_other_choices_of_kernel.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multi_class_classification.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_logistic_regression_vs_svms.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_supervised_learning.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_unsupervised_learning.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_application_of_clustering.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_example1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_example2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_example3.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_example4.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_algorithm_input.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_for_non_separated_clusters.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_k_means_optimization_objective.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_random_initialization_k_means.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_local_optima.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_random_initialization_k_means_func.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_the_value_of_k_elbow_method.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_the_value_of_k_downstream_performance.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_data_compression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_data_compression1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_data_visualization1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_data_visualization2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_data_visualization3.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_pca_problem_formulation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_pca_is_not_linear_regression.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_data_preprocessing.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_principal_component_analysis_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_principal_component_analysis_algorithm1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_pca_algorithm_summary.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_reconstruction_from_compressed_representation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_k1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_k2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_choosing_k3.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_supervised_learning_speedup.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_bad_use_of_pca.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_pca_is_sometimes_used_where_it_shouldn't_be.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_density_estimation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_example1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gaussian_distribution.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_gaussian_distribution_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_parameter_estimation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_density_estimation1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_example2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_the_importance_of_real_number_evaluation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_aircraft_engines_motivating_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_algorithm_evaluation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_vs_supervised_learning1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_vs_supervised_learning2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_non_gaussian_features.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_non_gaussian_features_example1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_error_analysis_for_anomaly_detection.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_motivating_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_distribution.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_examples1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_examples2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_examples3.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_examples4.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_examples5.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_examples6.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multivariate_gaussian_distribution_formula.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_anomaly_detection_with_the_multivariate_gaussian.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_relationship_to_original_model.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_relationship_to_original_model1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_example_predicting_movie_ratings.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_content_based_recommender_systems.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_problem_formulation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_optimization_objective.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_optimization_algorithm1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_problem_motivation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_optimization_algorithm2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_collaborative_filtering.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_collaborative_filtering_optimization_objective.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_collaborative_filtering_algorithm.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_collaborative_filtering1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_collaborative_filtering2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_finding_related_movies.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_users_who_have_not_rated_any_movies.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_mean_normalization.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_learning_with_large_datasets.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_linear_regression_with_gradient_descent.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_batch_vs_stochastic_gradient_descent.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_stochastic_gradient_descent.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_mini_batch_gradient_descent.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_checking_for_convergence1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_checking_for_convergence2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_stochastic_gradient_descent1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_online_learning.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_other_online_learning_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_map_reduce1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_map_reduce2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_map_reduce_and_summation_over_the_trainint_set.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_multi_core_machines.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_the_photo_ocr_problem.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_photo_ocr_pipeline.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_photo_ocr_pipeline1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_text_pedestrian_detection.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_supervised_learning_for_pedestrian_detection.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_sliding_window_detection1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_sliding_window_detection2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_sliding_window_detection3.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_text_detection1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_text_detection2.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_1d_sliding_window_for_character_segmentation.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_character_recognition.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_artificial_data_synthesis_for_photo_ocr.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_artificial_data_synthesis_for_photo_ocr1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_synthesizing_data_by_introducing_distortions.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_synthesizing_data_by_introducing_distortions_speech_recognition.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_synthesizing_data_by_introducing_distortions1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_discussion_on_getting_more_data.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_estimating_the_errors_due_to_each_component.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_another_ceiling_analysis_example.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_another_ceiling_analysis_example1.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_summary_main_topics.png">
<meta property="og:image" content="http://conglang.github.io/img/note_ml_coursera_machine_learning_completed.png">
<meta property="og:updated_time" content="2018-07-31T15:04:59.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning 课程笔记">
<meta name="twitter:description" content="Coursera上Machine Learning课程的笔记。介绍了Supervised Learning, Unsupervised Learning, Special applications/special topics, Advice on building a machine learning system等内容。">
<meta name="twitter:image" content="http://conglang.github.io/img/note_ml_coursera_introduction.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/astro.png">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/astro.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/astro.png">
          
        
    
    <!-- title -->
    <title>Machine Learning 课程笔记</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
  	<link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">
</head>

<body class="max-width mx-auto px3 ltr">    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/archives/">博文</a></li>
         
          <li><a href="/categories/">分类</a></li>
         
          <li><a href="/tags/">标签</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2015/08/19/note-work-smarter-not-harder-coursera/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2015/06/28/marcus-ai-recommendation/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&text=Machine Learning 课程笔记"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&is_video=false&description=Machine Learning 课程笔记"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Machine Learning 课程笔记&body=Check out this article: http://conglang.github.io/2015/07/15/note-machine-learning-coursera/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&name=Machine Learning 课程笔记&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text"> Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#welcome"><span class="toc-number">1.1.</span> <span class="toc-text"> Welcome</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#what-is-machine-learning"><span class="toc-number">1.2.</span> <span class="toc-text"> What is machine learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#supervised-learning"><span class="toc-number">1.3.</span> <span class="toc-text"> Supervised Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#unsupervised-learning"><span class="toc-number">1.4.</span> <span class="toc-text"> Unsupervised Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear-regression-with-one-variable"><span class="toc-number">2.</span> <span class="toc-text"> Linear Regression with One Variable</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#model-representation"><span class="toc-number">2.1.</span> <span class="toc-text"> Model representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function"><span class="toc-number">2.2.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-intuition"><span class="toc-number">2.3.</span> <span class="toc-text"> Cost function intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent"><span class="toc-number">2.4.</span> <span class="toc-text"> Gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-for-linear-regression"><span class="toc-number">2.5.</span> <span class="toc-text"> Gradient descent for linear regression</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear-regression-with-multiple-variables"><span class="toc-number">3.</span> <span class="toc-text"> Linear Regression with Multiple Variables</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#multiple-features"><span class="toc-number">3.1.</span> <span class="toc-text"> Multiple features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-for-multiple-variables"><span class="toc-number">3.2.</span> <span class="toc-text"> Gradient descent for multiple variables</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-in-practice-i-feature-scaling"><span class="toc-number">3.3.</span> <span class="toc-text"> Gradient descent in practice I: Feature Scaling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-in-practice-ii-learning-rate"><span class="toc-number">3.4.</span> <span class="toc-text"> Gradient descent in practice II: Learning rate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#features-and-polynomial-regression"><span class="toc-number">3.5.</span> <span class="toc-text"> Features and polynomial regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#normal-equation"><span class="toc-number">3.6.</span> <span class="toc-text"> Normal equation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#normal-equation-and-non-invertibility"><span class="toc-number">3.7.</span> <span class="toc-text"> Normal equation and non-invertibility</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#logistic-regression"><span class="toc-number">4.</span> <span class="toc-text"> Logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#classification"><span class="toc-number">4.1.</span> <span class="toc-text"> Classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hypothesis-representation"><span class="toc-number">4.2.</span> <span class="toc-text"> Hypothesis Representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#decision-boundary"><span class="toc-number">4.3.</span> <span class="toc-text"> Decision boundary</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-2"><span class="toc-number">4.4.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#simplified-cost-function-and-gradient-descent"><span class="toc-number">4.5.</span> <span class="toc-text"> Simplified cost function and gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#advanced-optimization"><span class="toc-number">4.6.</span> <span class="toc-text"> Advanced optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-class-classification-one-vs-all"><span class="toc-number">4.7.</span> <span class="toc-text"> Multi-class classification: One-vs-all</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#regularization"><span class="toc-number">5.</span> <span class="toc-text"> Regularization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#the-problem-of-overfitting"><span class="toc-number">5.1.</span> <span class="toc-text"> The problem of overfitting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-3"><span class="toc-number">5.2.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regularized-linear-regression"><span class="toc-number">5.3.</span> <span class="toc-text"> Regularized linear regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regularized-logistic-regression"><span class="toc-number">5.4.</span> <span class="toc-text"> Regularized logistic regression</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#neural-networks-representation"><span class="toc-number">6.</span> <span class="toc-text"> Neural Networks Representation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#non-linear-hypotheses"><span class="toc-number">6.1.</span> <span class="toc-text"> Non-linear hypotheses</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#neurons-and-the-brain"><span class="toc-number">6.2.</span> <span class="toc-text"> Neurons and the brain</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-representation-2"><span class="toc-number">6.3.</span> <span class="toc-text"> Model representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#examples-and-intuitions"><span class="toc-number">6.4.</span> <span class="toc-text"> Examples and intuitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-class-classification"><span class="toc-number">6.5.</span> <span class="toc-text"> Multi-class classification</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#neural-networks-learning"><span class="toc-number">7.</span> <span class="toc-text"> Neural Networks Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-4"><span class="toc-number">7.1.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backpropagation-algorithm"><span class="toc-number">7.2.</span> <span class="toc-text"> Backpropagation algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backpropagation-intuition"><span class="toc-number">7.3.</span> <span class="toc-text"> Backpropagation intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#implementation-note-unrolling-parameters"><span class="toc-number">7.4.</span> <span class="toc-text"> Implementation note: Unrolling parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-checking"><span class="toc-number">7.5.</span> <span class="toc-text"> Gradient checking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#random-initialization"><span class="toc-number">7.6.</span> <span class="toc-text"> Random initialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#putting-it-together"><span class="toc-number">7.7.</span> <span class="toc-text"> Putting it together</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backpropagation-example-autonomous-driving"><span class="toc-number">7.8.</span> <span class="toc-text"> Backpropagation example: Autonomous driving</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#advice-for-applying-machine-learning"><span class="toc-number">8.</span> <span class="toc-text"> Advice for Applying Machine Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#deciding-what-to-try-next"><span class="toc-number">8.1.</span> <span class="toc-text"> Deciding what to try next</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#evaluating-a-hypothesis"><span class="toc-number">8.2.</span> <span class="toc-text"> Evaluating a hypothesis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-selection-and-trainingvalidationtest-sets"><span class="toc-number">8.3.</span> <span class="toc-text"> Model selection and training/validation/test sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#diagnosing-bias-vs-variance"><span class="toc-number">8.4.</span> <span class="toc-text"> Diagnosing bias vs. variance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regularization-and-biasvariance"><span class="toc-number">8.5.</span> <span class="toc-text"> Regularization and bias/variance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#learning-curves"><span class="toc-number">8.6.</span> <span class="toc-text"> Learning curves</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#deciding-what-to-try-nextrevisited"><span class="toc-number">8.7.</span> <span class="toc-text"> Deciding what to try next(revisited)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#machine-learning-system-design"><span class="toc-number">9.</span> <span class="toc-text"> Machine Learning System Design</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prioritizing-what-to-work-on-spam-classification-example"><span class="toc-number">9.1.</span> <span class="toc-text"> Prioritizing what to work on: Spam classification example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#error-analysis"><span class="toc-number">9.2.</span> <span class="toc-text"> Error analysis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#error-metrics-for-skewed-classes"><span class="toc-number">9.3.</span> <span class="toc-text"> Error metrics for skewed classes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#trading-off-precision-and-recall"><span class="toc-number">9.4.</span> <span class="toc-text"> Trading off precision and recall</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#data-for-machine-learning"><span class="toc-number">9.5.</span> <span class="toc-text"> Data for machine learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#support-vector-machines"><span class="toc-number">10.</span> <span class="toc-text"> Support Vector Machines</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#optimization-objective"><span class="toc-number">10.1.</span> <span class="toc-text"> Optimization objective</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#large-margin-intuition"><span class="toc-number">10.2.</span> <span class="toc-text"> Large Margin Intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-mathematics-behind-large-margin-classification"><span class="toc-number">10.3.</span> <span class="toc-text"> The mathematics behind large margin classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kernals"><span class="toc-number">10.4.</span> <span class="toc-text"> Kernals</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#using-an-svm"><span class="toc-number">10.5.</span> <span class="toc-text"> Using an SVM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#clustering"><span class="toc-number">11.</span> <span class="toc-text"> Clustering</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#unsupervised-learning-introduction"><span class="toc-number">11.1.</span> <span class="toc-text"> Unsupervised learning introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means-algorithm"><span class="toc-number">11.2.</span> <span class="toc-text"> K-means algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimization-objective-2"><span class="toc-number">11.3.</span> <span class="toc-text"> Optimization Objective</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#random-initialization-2"><span class="toc-number">11.4.</span> <span class="toc-text"> Random initialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#choosing-the-number-of-clusters"><span class="toc-number">11.5.</span> <span class="toc-text"> Choosing the number of clusters</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dimensionality-reduction"><span class="toc-number">12.</span> <span class="toc-text"> Dimensionality Reduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation-i-data-compression"><span class="toc-number">12.1.</span> <span class="toc-text"> Motivation I: Data Compression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation-ii-data-visualization"><span class="toc-number">12.2.</span> <span class="toc-text"> Motivation II: Data Visualization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#principal-component-analysis-problem-formulation"><span class="toc-number">12.3.</span> <span class="toc-text"> Principal Component Analysis problem formulation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#principal-component-analysis-algorithm"><span class="toc-number">12.4.</span> <span class="toc-text"> Principal Component Analysis algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reconstruction-from-compressed-representation"><span class="toc-number">12.5.</span> <span class="toc-text"> Reconstruction from compressed representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#choosing-the-number-of-principal-components"><span class="toc-number">12.6.</span> <span class="toc-text"> Choosing the Number of Principal Components</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#advice-for-applying-pca"><span class="toc-number">12.7.</span> <span class="toc-text"> Advice for applying PCA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#anomaly-detection"><span class="toc-number">13.</span> <span class="toc-text"> Anomaly Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#problem-motivation"><span class="toc-number">13.1.</span> <span class="toc-text"> Problem motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gaussian-distribution"><span class="toc-number">13.2.</span> <span class="toc-text"> Gaussian distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#algorithm"><span class="toc-number">13.3.</span> <span class="toc-text"> Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#developing-and-evaluating-an-anomaly-detection-system"><span class="toc-number">13.4.</span> <span class="toc-text"> Developing and evaluating an anomaly detection system</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#anomaly-detection-vs-supervised-learning"><span class="toc-number">13.5.</span> <span class="toc-text"> Anomaly detection vs. supervised learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#choosing-what-features-to-use"><span class="toc-number">13.6.</span> <span class="toc-text"> Choosing what features to use</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multivariate-gaussian-distribution"><span class="toc-number">13.7.</span> <span class="toc-text"> Multivariate Gaussian distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#anomaly-detection-using-the-multivariate-gaussian-distribution"><span class="toc-number">13.8.</span> <span class="toc-text"> Anomaly detection using the multivariate Gaussian distribution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#recommender-systems"><span class="toc-number">14.</span> <span class="toc-text"> Recommender Systems</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#problem-formulation"><span class="toc-number">14.1.</span> <span class="toc-text"> Problem formulation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#content-based-recommendations"><span class="toc-number">14.2.</span> <span class="toc-text"> Content-based recommendations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#collaborative-filtering"><span class="toc-number">14.3.</span> <span class="toc-text"> Collaborative filtering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#collaborative-filtering-algorithm"><span class="toc-number">14.4.</span> <span class="toc-text"> Collaborative filtering algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vectorization-low-rank-matrix-factorization"><span class="toc-number">14.5.</span> <span class="toc-text"> Vectorization: Low rank matrix factorization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#finding-related-movies"><span class="toc-number">14.6.</span> <span class="toc-text"> Finding related movies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#implementational-detail-mean-normalization"><span class="toc-number">14.7.</span> <span class="toc-text"> Implementational detail: Mean normalization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#large-scale-machine-learning"><span class="toc-number">15.</span> <span class="toc-text"> Large Scale Machine Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#learning-with-large-datasets"><span class="toc-number">15.1.</span> <span class="toc-text"> Learning with large datasets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descent"><span class="toc-number">15.2.</span> <span class="toc-text"> Stochastic gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mini-batch-gradient-descent"><span class="toc-number">15.3.</span> <span class="toc-text"> Mini-batch gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descent-convergence"><span class="toc-number">15.4.</span> <span class="toc-text"> Stochastic gradient descent convergence</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#online-learning"><span class="toc-number">15.5.</span> <span class="toc-text"> Online learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#map-reduce-and-data-parallelism"><span class="toc-number">15.6.</span> <span class="toc-text"> Map-reduce and data parallelism</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#application-example-photo-ocr"><span class="toc-number">16.</span> <span class="toc-text"> Application Example Photo OCR</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#problem-description-and-pipeline"><span class="toc-number">16.1.</span> <span class="toc-text"> Problem description and pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sliding-windows"><span class="toc-number">16.2.</span> <span class="toc-text"> Sliding windows</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#getting-lots-of-data-artificial-data-synthesis"><span class="toc-number">16.3.</span> <span class="toc-text"> Getting lots of data: Artificial data synthesis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ceiling-analysis-what-part-of-the-pipeline-to-work-on-next"><span class="toc-number">16.4.</span> <span class="toc-text"> Ceiling analysis: What part of the pipeline to work on next</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conclusion"><span class="toc-number">17.</span> <span class="toc-text"> Conclusion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#summary-and-thank-you"><span class="toc-number">17.1.</span> <span class="toc-text"> Summary and Thank you</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index my4">
        
        
        
          <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Machine Learning 课程笔记
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">A Stellar Hiker</span>
      </span>
      
    <div class="postdate">
        <time datetime="2015-07-15T12:20:36.000Z" itemprop="datePublished">2015-07-15</time>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Course/">Course</a>, <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>Coursera上的<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">机器学习公开课</a>，据说是<a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">实际授课</a>的弱化版本。<br>
<img src="/img/note_ml_coursera_introduction.png" alt="Image Loading"></p>
<hr>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<h3 id="welcome"><a class="markdownIt-Anchor" href="#welcome"></a> Welcome</h3>
<p><strong>Machine Learning</strong></p>
<ul>
<li>Grew out of work in AI</li>
<li>New capability for computers</li>
</ul>
<p><strong>Examples:</strong></p>
<ul>
<li>Database mining<br>
Large datasets from growth of automation/web.<br>
E.g., Web click data, medical records, biology, engineering.</li>
<li>Applications can’t program by hand<br>
E.g., Autonomous helicopter, handwriting recognition, most of Natural Language Processing(NLP), Computer Vision.</li>
<li>Self-customizing programs<br>
E.g., Amazon, Netflix product recommendations.</li>
<li>Understanding human learning(brain, real AI).</li>
</ul>
<h3 id="what-is-machine-learning"><a class="markdownIt-Anchor" href="#what-is-machine-learning"></a> What is machine learning</h3>
<p><strong>Machine Learning definition</strong></p>
<ul>
<li>Arthur Samuel(1959). Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.</li>
<li>Tom Mitchell(1998) Well-posed Learning Problem: A computer program is said to learn from <strong>experience E</strong> with respect to some <strong>task T</strong> and some <strong>performance measure P</strong>, if its performance on T, as measured by P, improves with experience E.</li>
</ul>
<p><strong>Machine learning algorithms:</strong></p>
<ul>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
</ul>
<p>Others: Reinforcement learning, recommender systems.<br>
Also talk about: Practical advice for applying learning algorithms.</p>
<h3 id="supervised-learning"><a class="markdownIt-Anchor" href="#supervised-learning"></a> Supervised Learning</h3>
<p>“right answers” given.<br>
<img src="/img/note_ml_coursera_supervised_learning_housing_price_prediction.png" alt="Regression"><br>
<strong>Regression</strong>: Predict continuous valued output.(E.g. Housing price prediction.)<br>
<img src="/img/note_ml_coursera_supervised_learning_breast_cancer.png" alt="Classification"><br>
<strong>Classification</strong>: Discrete valued output(0 or 1).(E.g. Breast cancer(malignant, benign).)</p>
<h3 id="unsupervised-learning"><a class="markdownIt-Anchor" href="#unsupervised-learning"></a> Unsupervised Learning</h3>
<p>E.g., Related news, Genes, Organize computing clusters, Social network analysis, Market segmentation, Astronomical data analysis, Cocktail party problem(分辨混合音源中的不同声音).</p>
<hr>
<h2 id="linear-regression-with-one-variable"><a class="markdownIt-Anchor" href="#linear-regression-with-one-variable"></a> Linear Regression with One Variable</h2>
<h3 id="model-representation"><a class="markdownIt-Anchor" href="#model-representation"></a> Model representation</h3>
<p>Supervised Learning: Given the “right answer” for each example in the data.<br>
Regression Problem: Predict real-valued output.<br>
<img src="/img/note_ml_coursera_training_set_of_housing_prices.png" alt="Notation"><br>
Notation:<br>
<strong>m</strong> = Number of training examples<br>
<strong>x</strong>’s = “input” variable / features<br>
<strong>y</strong>’s = “output” variable / “target” variable<br>
<img src="/img/note_ml_coursera_housing_price_process.png" alt="Process"></p>
<h3 id="cost-function"><a class="markdownIt-Anchor" href="#cost-function"></a> Cost function</h3>
<p><strong>Hypothesis</strong>:  <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi mathvariant="normal">Θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo>+</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub><mi>x</mi></mrow><annotation encoding="application/x-tex">h_{\Theta}(x)={\Theta}_0+{\Theta}_1x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">Θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">x</span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">{\Theta}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>'s: Parameters</p>
<p><img src="/img/note_ml_coursera_cost_function_eg.png" alt="Image Loading"></p>
<p>Idea:<br>
Choose <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi><mn>0</mn></mrow><annotation encoding="application/x-tex">\Theta0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span><span class="mord mathrm">0</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">\Theta1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span><span class="mord mathrm">1</span></span></span></span> so that <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi mathvariant="normal">Θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\Theta}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">Θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> is close to <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span> for our training examples <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord mathit">x</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>.</p>
<h3 id="cost-function-intuition"><a class="markdownIt-Anchor" href="#cost-function-intuition"></a> Cost function intuition</h3>
<p><img src="/img/note_ml_coursera_cost_function_intuition_i.png" alt="Image Loading"><br>
用很多不同的两值计算出误差，画一张误差表，可以看出走势图。<br>
<img src="/img/note_ml_coursera_j_3d.png" alt="误差图的三维表示"><br>
可以用Contour figure来表示。同一条曲线上误差值相同。<br>
<img src="/img/note_ml_coursera_cost_function_contour1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_cost_function_contour4.png" alt="Image Loading"></p>
<h3 id="gradient-descent"><a class="markdownIt-Anchor" href="#gradient-descent"></a> Gradient descent</h3>
<p>Have some function <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">J({\Theta}_0,{\Theta}_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></p>
<p>Want <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mrow><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub></mrow></msub><mi>J</mi><mo>(</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">{min}_{ {\Theta}_0,{\Theta}_1 } J({\Theta}_0,{\Theta}_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit">m</span><span class="mord mathit">i</span><span class="mord mathit">n</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord"><span class="mord scriptstyle cramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord scriptstyle cramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></p>
<p><strong>Outline:</strong></p>
<ul>
<li>Start with some <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{\Theta}_0, {\Theta}_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></li>
<li>Keep changing <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{\Theta}_0,{\Theta}_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> to reduce <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">Θ</mi></mrow><mn>1</mn></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">J({\Theta}_0,{\Theta}_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">Θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span> until we hopefully end up at a minimum</li>
</ul>
<p>起点稍有不一样就可能结果不同，有Local optima问题。<br>
<img src="/img/note_ml_coursera_gradient_descent_1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_gradient_descent_2.png" alt="Image Loading"></p>
<p><strong>Algorithm:</strong><br>
每个参数单独一点点聚合。<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>表示Learning rate，是一个调节变量。注意要先同时计算差值，然后再同时更新参数。<br>
<img src="/img/note_ml_coursera_gradient_descent_algorithm.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_gradient_descent_alpha.png" alt="Image Loading"></p>
<p>Gradient descent can converge to a local minimum, even with the learning rate <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span> fixed.因为随着误差减小，即使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>固定，每次调整的数量也会变小。<br>
As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span> over time.</p>
<h3 id="gradient-descent-for-linear-regression"><a class="markdownIt-Anchor" href="#gradient-descent-for-linear-regression"></a> Gradient descent for linear regression</h3>
<p><img src="/img/note_ml_coursera_gradient_descent_for_linear_regression_algorithm.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_gradient_descent_for_linear_regression_algorithm1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_gradient_descent_for_linear_regression_algorithm2.png" alt="Image Loading"></p>
<p>“Batch” Gradient Descent: Each step of gradient descent uses all the training examples.</p>
<hr>
<h2 id="linear-regression-with-multiple-variables"><a class="markdownIt-Anchor" href="#linear-regression-with-multiple-variables"></a> Linear Regression with Multiple Variables</h2>
<h3 id="multiple-features"><a class="markdownIt-Anchor" href="#multiple-features"></a> Multiple features</h3>
<p>之前X只有一个维度，现在考虑X有多维的情况。<br>
<img src="/img/note_ml_coursera_multiple_features_example.png" alt="Image Loading"><br>
也称作Multivariate linear regression。</p>
<h3 id="gradient-descent-for-multiple-variables"><a class="markdownIt-Anchor" href="#gradient-descent-for-multiple-variables"></a> Gradient descent for multiple variables</h3>
<p>(注意以下公式的vectorize。有利计算，要多尝试把这些都看做向量、矩阵来计算。)<br>
<img src="/img/note_ml_coursera_gradient_descent_multivariable_formula.png" alt="Image Loading"><br>
一维只是多维的一个特例。<br>
<img src="/img/note_ml_coursera_gradient_descent_multi_formula.png" alt="Image Loading"></p>
<h3 id="gradient-descent-in-practice-i-feature-scaling"><a class="markdownIt-Anchor" href="#gradient-descent-in-practice-i-feature-scaling"></a> Gradient descent in practice I: Feature Scaling</h3>
<p><strong>Feature Scaling</strong>: Get every feature into approximately a <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mn>1</mn><mo>⩽</mo><msub><mi>x</mi><mi>i</mi></msub><mo>⩽</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1 \leqslant x_i \leqslant 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord">−</span><span class="mord mathrm">1</span><span class="mrel amsrm">⩽</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel amsrm">⩽</span><span class="mord mathrm">1</span></span></span></span> range.<br>
E.g. :<br>
原来的取值范围，画出来的J的Coutour figure会是一个拉的很长的细长形状，converge的时候会花费很多时间才能走到中心minimum。<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>(</mo><mn>0</mn><mo>−</mo><mn>2</mn><mn>0</mn><mn>0</mn><mn>0</mn><msup><mrow><mi>f</mi><mi>e</mi><mi>e</mi><mi>t</mi></mrow><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">x_1 = size(0-2000 {feet}^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mopen">(</span><span class="mord mathrm">0</span><span class="mbin">−</span><span class="mord mathrm">2</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">e</span><span class="mord mathit">e</span><span class="mord mathit">t</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mi>n</mi><mi>u</mi><mi>m</mi><mi>b</mi><mi>e</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>b</mi><mi>e</mi><mi>d</mi><mi>r</mi><mi>o</mi><mi>o</mi><mi>m</mi><mi>s</mi><mo>(</mo><mn>1</mn><mo>−</mo><mn>5</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">x_2 = number of bedrooms(1-5)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit">n</span><span class="mord mathit">u</span><span class="mord mathit">m</span><span class="mord mathit">b</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">b</span><span class="mord mathit">e</span><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit">o</span><span class="mord mathit">m</span><span class="mord mathit">s</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathrm">5</span><span class="mclose">)</span></span></span></span><br>
将取值均一化。<br>
x_1 = \cfrac{size({feet}^2)}{2000} 和 x_2 = \cfrac{number of bedrooms}{5}</p>
<p><strong>Mean normalization</strong>: Replace <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> with <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mrow><mi>μ</mi></mrow><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i- {\mu}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.58333em;"></span><span class="strut bottom" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">−</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit">μ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> to make features have approximately zero mean (Do not apply to <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_0=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span>).<br>
E.g.:<br>
x_1= \cfrac{size-1000}{2000} 范围变为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn><mo>⩽</mo><msub><mi>x</mi><mn>1</mn></msub><mo>⩽</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">-0.5 \leqslant x_1 \leqslant 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord">−</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span><span class="mrel amsrm">⩽</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel amsrm">⩽</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span>。<br>
x_2= \cfrac{bedrooms-2}{5} 范围变为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn><mo>⩽</mo><msub><mi>x</mi><mn>2</mn></msub><mo>⩽</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">-0.5 \leqslant x_2 \leqslant 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord">−</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span><span class="mrel amsrm">⩽</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel amsrm">⩽</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span>。</p>
<h3 id="gradient-descent-in-practice-ii-learning-rate"><a class="markdownIt-Anchor" href="#gradient-descent-in-practice-ii-learning-rate"></a> Gradient descent in practice II: Learning rate</h3>
<p><strong>Debugging: Making sure gradient descent is working correctly.</strong><br>
确定每次迭代<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>都是变小的。当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>小于某个值比如<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord"><span class="mord mathrm">0</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord">−</span><span class="mord mathrm">3</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>时停止迭代，但是这个值很难把握，一般也可以还是看图说话。</p>
<p><strong>How to choose learning rate <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>.</strong><br>
If <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span> is too small: slow convergence.<br>
If <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span> is too large: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> may not decrease on every iteration; may not converge. (Slow converge also possible.)<br>
Too choose <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>, try: …, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, …</p>
<h3 id="features-and-polynomial-regression"><a class="markdownIt-Anchor" href="#features-and-polynomial-regression"></a> Features and polynomial regression</h3>
<p>多项式回归<br>
对于房子的价格来说，可能有多项影响因素，如长、宽等。<br>
从图中看到，size和price的关系并不是线性关系，如果是二次方的关系曲线末端会变为下降也不太可能，所以可能是三次方的关系。<br>
<img src="/img/note_ml_coursera_polynomial_regression_house_price.png" alt="Image Loading"><br>
而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">{size}^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>的取值范围与<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">size</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.65952em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span></span></span></span>的取值范围相差太大了，不是最好的选择。这时我们想到，可以用开根号。<br>
于是可以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub><mo>+</mo><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub><mo>(</mo><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>)</mo><mo>+</mo><msub><mrow><mi>θ</mi></mrow><mn>2</mn></msub><msqrt><mrow><mo>(</mo><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>)</mo></mrow></msqrt></mrow><annotation encoding="application/x-tex">h_{\theta}(x)={\theta}_0+{\theta}_1(size)+{\theta}_2 \sqrt{(size)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9350050000000001em;"></span><span class="strut bottom" style="height:1.24001em;vertical-align:-0.3050049999999999em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.04500500000000007em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mopen">(</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span><span class="mclose">)</span></span></span><span style="top:-0.855005em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span></p>
<h3 id="normal-equation"><a class="markdownIt-Anchor" href="#normal-equation"></a> Normal equation</h3>
<p>除了用Gradient Descent逐步聚合求结果的方法，还有一种用数学公式求解<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>的方法。<br>
<strong>Normal equation</strong>: Method to solve for <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span> analytically.<br>
由于目的是求使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>最小的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>值，所以在该处<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>的斜率、微分是0，可以据此求解。<br>
<img src="/img/note_ml_coursera_normal_equation.png" alt="Image Loading"></p>
<p>示例：<br>
<img src="/img/note_ml_coursera_normal_equation_example.png" alt="Image Loading"></p>
<p><strong>公式</strong>就是：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi><mo>=</mo><msup><mrow><mo>(</mo><msup><mi>X</mi><mi>T</mi></msup><mi>X</mi><mo>)</mo></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>X</mi><mi>T</mi></msup><mi>y</mi></mrow><annotation encoding="application/x-tex">\theta = {(X^TX)}^{-1}X^Ty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9064389999999999em;"></span><span class="strut bottom" style="height:1.1564389999999998em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mrel">=</span><span class="mord"><span class="mord textstyle uncramped"><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span><span class="vlist"><span style="top:-0.45533099999999993em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span><br>
在Octave中的写法是<code>pinv(X'*X)*X'*y</code>。</p>
<p>与Gradient Descent做<strong>比较</strong>：<br>
<img src="/img/note_ml_coursera_gd_ne_compare.png" alt="Image Loading"></p>
<h3 id="normal-equation-and-non-invertibility"><a class="markdownIt-Anchor" href="#normal-equation-and-non-invertibility"></a> Normal equation and non-invertibility</h3>
<p>如果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><msup><mi>X</mi><mi>T</mi></msup><mi>X</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(X^TX)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span>是不可逆的(singular/degenerate)，在Octave中使用<code>pinv(X'*X)*X'*y</code>仍然可以求出来。<br>
但这时我们最好检查一下自己的数据。可能的原因有：</p>
<ul>
<li>Redundant features (linearly dependent). 如x1是size在平方英尺下的值，x2是size在平方米下的值。</li>
<li>Too many features. 比如<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mo>⩽</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \leqslant n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.63667em;"></span><span class="strut bottom" style="height:0.7733399999999999em;vertical-align:-0.13667em;"></span><span class="base textstyle uncramped"><span class="mord mathit">m</span><span class="mrel amsrm">⩽</span><span class="mord mathit">n</span></span></span></span>，此时应该删除一些feature，或者使用regularization。</li>
</ul>
<hr>
<h2 id="logistic-regression"><a class="markdownIt-Anchor" href="#logistic-regression"></a> Logistic Regression</h2>
<h3 id="classification"><a class="markdownIt-Anchor" href="#classification"></a> Classification</h3>
<p>例子：</p>
<ul>
<li>Email: Spam / Not Spam?</li>
<li>Online Transactions: Fraudulent(Yes / No)?</li>
<li>Tumor: Malignant / Benign?</li>
</ul>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>∈</mo><mo>{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>}</mo></mrow><annotation encoding="application/x-tex">y \in \{ 0,1 \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">∈</span><span class="mopen">{</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose">}</span></span></span></span><br>
0: “Negative Class” (e.g., benign tumor)<br>
1: “Positive Class” (e.g., malignant tumor)</p>
<p>不适合用linear regression解决，应该用Logistic Regression。</p>
<h3 id="hypothesis-representation"><a class="markdownIt-Anchor" href="#hypothesis-representation"></a> Hypothesis Representation</h3>
<p><strong>Logistic Regression Model</strong><br>
Want <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mo>⩽</mo><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>⩽</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \leqslant h_{\theta}(x) \leqslant 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">0</span><span class="mrel amsrm">⩽</span><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel amsrm">⩽</span><span class="mord mathrm">1</span></span></span></span></p>
<p>Sigmoid function/Logistic function: h_{\theta}(x) = g({\theta}^Tx) = \cfrac{1}{1+e^{ -{\theta}^Tx} }</p>
<p>它的曲线图类似<br>
<img src="/img/note_ml_coursera_sigmoid_function_line.png" alt="Image Loading"><br>
<strong>Interpretation of Hypothesis Output</strong><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\theta}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> = estimated probability that y=1 on input x</p>
<p>Example:<br>
If <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>=</mo><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mrow><mn>1</mn></mrow></mtd></mtr><mtr><mtd><mrow><mi>t</mi><mi>u</mi><mi>m</mi><mi>o</mi><mi>r</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">x = \begin{bmatrix} x_0 \\ x_1 \end{bmatrix} = \begin{bmatrix} 1 \\ tumorSize \end{bmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.45em;"></span><span class="strut bottom" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span><span class="mrel">=</span><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist"><span style="top:-0.6099999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:0.5900000000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size3">]</span></span></span><span class="mrel">=</span><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist"><span style="top:-0.6099999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle uncramped"><span class="mord mathrm">1</span></span></span><span style="top:0.5900000000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit">u</span><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="mord mathit">e</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn></mrow><annotation encoding="application/x-tex">h_{\theta}(x) = 0.7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">7</span></span></span></span><br>
Tell patient that 70% chance of tumor being malignant.</p>
<p>&quot;probability that y = 1, given x, parameterized by <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>&quot;</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\theta}(x) = P(y=1|x; \theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">∣</span><span class="mord mathit">x</span><span class="mpunct">;</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>y</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><mi>θ</mi><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo>(</mo><mi>y</mi><mo>=</mo><mn>0</mn><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">P(y=0|x; \theta) = 1 - P(y=0|x; \theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">∣</span><span class="mord mathit">x</span><span class="mpunct">;</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord mathrm">0</span><span class="mord mathrm">∣</span><span class="mord mathit">x</span><span class="mpunct">;</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></p>
<h3 id="decision-boundary"><a class="markdownIt-Anchor" href="#decision-boundary"></a> Decision boundary</h3>
<p><strong>Logistic regression</strong><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>g</mi><mo>(</mo><msup><mrow><mi>θ</mi></mrow><mi>T</mi></msup><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\theta}(x) = g({\theta}^Tx)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> 和 g(z) = \cfrac{1}{1+e^{-z} }。</p>
<p><img src="/img/note_ml_coursera_sigmoid_function_line.png" alt="Image Loading"></p>
<p>Suppose predict “y = 1” if <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>⩾</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">h_{\theta}(x) \geqslant 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel amsrm">⩾</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span>。g(z)大于等于0.5，是当z大于等于0时。带入公式，即是当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow><mi>θ</mi></mrow><mi>T</mi></msup><mi>x</mi><mo>⩾</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">{\theta}^Tx \geqslant 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:0.9780009999999999em;vertical-align:-0.13667em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">x</span><span class="mrel amsrm">⩾</span><span class="mord mathrm">0</span></span></span></span>时。</p>
<p>同理，predict “y = 0” if <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>&lt;</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">h_{\theta}(x) &lt; 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">&lt;</span><span class="mord mathrm">0</span><span class="mord mathrm">.</span><span class="mord mathrm">5</span></span></span></span> 也既是当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow><mi>θ</mi></mrow><mi>T</mi></msup><mi>x</mi><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">{\theta}^T x &lt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:0.880431em;vertical-align:-0.0391em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">x</span><span class="mrel">&lt;</span><span class="mord mathrm">0</span></span></span></span>时。</p>
<p><strong>Decision Boundary</strong><br>
<img src="/img/note_ml_decision_boundary1.png" alt="Image Loading"><br>
为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_0, {\theta}_1, {\theta}_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>分别取值-3,1,1。画出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">x_1+x_2=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">3</span></span></span></span>的图，这就是Decision boundary。</p>
<p><strong>Non-linear decision boundaries</strong><br>
<img src="/img/note_ml_non_linear_decision_boundaries.png" alt="Image Loading"><br>
对于复杂一些的公式也是一样，分别取值-1,0,0,1,1。画出曲线图，即是Decisioin boundary。</p>
<h3 id="cost-function-2"><a class="markdownIt-Anchor" href="#cost-function-2"></a> Cost function</h3>
<p><img src="/img/note_ml_coursera_logistic_regression_cost_function.png" alt="Image Loading"></p>
<p><strong>Logistic regression cost function</strong><br>
<img src="/img/note_ml_coursera_logistic_regression_cost_function_formula.png" alt="Image Loading"><br>
x轴是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\theta}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span>，y轴是Cost。<br>
<img src="/img/note_ml_coursera_logistic_regression_cost_function_y1.png" alt="y=1的情况"><br>
<img src="/img/note_ml_coursera_logistic_regression_cost_function_y0.png" alt="y=0的情况"></p>
<h3 id="simplified-cost-function-and-gradient-descent"><a class="markdownIt-Anchor" href="#simplified-cost-function-and-gradient-descent"></a> Simplified cost function and gradient descent</h3>
<p><strong>Logistic regression cost function</strong><br>
<img src="/img/note_ml_coursera_logistic_regression_cost_function_review.png" alt="Image Loading"><br>
其中的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>作为比较，Linear regression的是这样的：<br>
<img src="/img/note_ml_coursera_linear_regression_j.png" alt="Linear regression J"><br>
而Logistic regression的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>可以简化为：<br>
<img src="/img/note_ml_coursera_logistic_regression_cost_function_changed.png" alt="Image Loading"><br>
目标就是求得使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>最小的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>。</p>
<p><strong>Gradient Descent</strong><br>
<img src="/img/note_ml_coursera_logistic_regression_gradient_descent1.png" alt="Image Loading"><br>
即<br>
<img src="/img/note_ml_coursera_logistic_regression_gradient_descent2.png" alt="Image Loading"><br>
Algorithm looks identical to linear regression!</p>
<h3 id="advanced-optimization"><a class="markdownIt-Anchor" href="#advanced-optimization"></a> Advanced optimization</h3>
<p><strong>Optimization algorithm</strong><br>
<img src="/img/note_ml_coursera_optimization_algorithm.png" alt="Image Loading"><br>
这些高级函数在octave里已有实现。<br>
一个例子，在octave里：<br>
<img src="/img/note_ml_coursera_optimization_algorithm_example.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_optimization_algorithm_implement.png" alt="Image Loading"></p>
<h3 id="multi-class-classification-one-vs-all"><a class="markdownIt-Anchor" href="#multi-class-classification-one-vs-all"></a> Multi-class classification: One-vs-all</h3>
<p><strong>Multiclass classification</strong><br>
Examples:<br>
Email foldering/tagging: Work, Friends, Family, Hobby<br>
Medical diagrams: Not ill, Cold, Flu<br>
Weather: Sunny, Cloudy, Rain, Snow<br>
<img src="/img/note_ml_coursera_multiclass_classification.png" alt="Image Loading"><br>
处理多class要用到one-vs-all方法。</p>
<p><strong>One-vs-all (one-vs-rest):</strong><br>
每次针对其中一组和其他组。如下图就分成3个Classifier。<br>
<img src="/img/note_ml_coursera_multiclass_classification_onevsall.png" alt="Image Loading"><br>
Train a logistic regression classifier <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>h</mi><mrow><mi>θ</mi></mrow><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\theta}^{(i)}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.0448em;"></span><span class="strut bottom" style="height:1.3461079999999999em;vertical-align:-0.30130799999999996em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.30130799999999996em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span style="top:-0.5197999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> for each class <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.65952em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">i</span></span></span></span> to predict the probability that <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>i</mi></mrow><annotation encoding="application/x-tex">y=i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord mathit">i</span></span></span></span>.</p>
<p>On a new input <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span>, to make a prediction, pick the class <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.65952em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">i</span></span></span></span> that maximazes.<br>
<img src="/img/note_ml_coursera_logistic_regression_one_vs_all.png" alt="Image Loading"></p>
<hr>
<h2 id="regularization"><a class="markdownIt-Anchor" href="#regularization"></a> Regularization</h2>
<h3 id="the-problem-of-overfitting"><a class="markdownIt-Anchor" href="#the-problem-of-overfitting"></a> The problem of overfitting</h3>
<p><strong>Overfitting:</strong> If we have too many features, the learned hypothesis may fit the training set very well (<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">J(\theta)=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathrm">0</span></span></span></span>), but fail to generalize to new examples (predict prices on new examples).</p>
<p>Example: Linear regression (housing prices)<br>
<img src="/img/note_ml_coursera_overfitting_linear_regression.png" alt="Image Loading"><br>
Example: Logistic regression<br>
<img src="/img/note_ml_coursera_overfitting_logistic_regression.png" alt="Image Loading"></p>
<p><strong>Addressing overfitting:</strong><br>
如果feature很少，可以画出图。如果feature太多，有两个选择：</p>
<ol>
<li>Reduce number of features.<br>
Manually select which features to keep.<br>
Model selection algorithm (later in course).</li>
<li>Regularization.<br>
Keep all the features, but reduce magnitude/values of parameters <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">{\theta}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>.<br>
Works well when we have a lot of features, each of which contributes a bit to predicting <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span>.</li>
</ol>
<h3 id="cost-function-3"><a class="markdownIt-Anchor" href="#cost-function-3"></a> Cost function</h3>
<p><strong>Intuition</strong><br>
<img src="/img/note_ml_coursera_regularization_intuition.png" alt="Image Loading"><br>
如果想让这个式子的值很小那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">4</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>必须很小。</p>
<p><strong>Regularization</strong><br>
Small values for parameters <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{\theta}_0, {\theta}_1, ..., {\theta}_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></p>
<ul>
<li>“Simpler” hypothesis</li>
<li>Less prone to overfitting</li>
</ul>
<p>Housing:</p>
<ul>
<li>Features: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mrow><mn>1</mn><mn>0</mn><mn>0</mn></mrow></msub></mrow><annotation encoding="application/x-tex">x_1, x_2, ..., x_{100}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">1</span><span class="mord mathrm">0</span><span class="mord mathrm">0</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></li>
<li>Parameters: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub><mn>0</mn><mn>0</mn></mrow><annotation encoding="application/x-tex">{\theta}_0, {\theta}_1, {\theta}_2, ..., {\theta}_100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">0</span><span class="mord mathrm">0</span></span></span></span></li>
</ul>
<p>由于不知道应该减少哪些<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>，所以全部减少。<br>
<img src="/img/note_ml_coursera_regularization_formular.png" alt="Image Loading"><br>
如果<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span>特别大，那么从<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{\theta}_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>几乎都为0，那么<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mo>(</mo><mi>θ</mi><mo>)</mo><mo>=</mo><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">h(\theta)={\theta}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">h</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，是一条横线。不能消除overfitting，反而导致underfitting。对算法本身的执行没影响。Gradient descent会无法converge。</p>
<h3 id="regularized-linear-regression"><a class="markdownIt-Anchor" href="#regularized-linear-regression"></a> Regularized linear regression</h3>
<p><strong>Regularized linear regression</strong><br>
<img src="/img/note_ml_coursera_regularized_linear_regression.png" alt="Image Loading"></p>
<p><strong>Gradient descent</strong><br>
<img src="/img/note_ml_coursera_regularized_linear_regression_gradient_descent.png" alt="Image Loading"></p>
<p><strong>Normal equation</strong><br>
<img src="/img/note_ml_coursera_regularized_linear_regression_normal_equation.png" alt="Image Loading"></p>
<p><strong>Non-invertibility (optional/advanced)</strong><br>
<img src="/img/note_ml_coursera_regularized_linear_regression_non_invertibility.png" alt="Image Loading"></p>
<h3 id="regularized-logistic-regression"><a class="markdownIt-Anchor" href="#regularized-logistic-regression"></a> Regularized logistic regression</h3>
<p><strong>Regularized logistic regression</strong><br>
<img src="/img/note_ml_coursera_regularized_logistic_regression.png" alt="Image Loading"></p>
<p><strong>Gradient descent</strong><br>
<img src="/img/note_ml_coursera_regularized_logistic_regression_gradient_descent.png" alt="Image Loading"></p>
<p><strong>Advanced optimization</strong><br>
<img src="/img/note_ml_coursera_regularized_logistic_regression_advanced_optimization.png" alt="Image Loading"></p>
<hr>
<h2 id="neural-networks-representation"><a class="markdownIt-Anchor" href="#neural-networks-representation"></a> Neural Networks Representation</h2>
<h3 id="non-linear-hypotheses"><a class="markdownIt-Anchor" href="#non-linear-hypotheses"></a> Non-linear hypotheses</h3>
<p>当feature很多的时候，计算起来简直麻烦上天。<br>
<img src="/img/note_ml_coursera_non_linear_classification.png" alt="Image Loading"></p>
<p>一个Computer Vision例子：<br>
<img src="/img/note_ml_coursera_nn_computervision_1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_nn_computervision_2.png" alt="Image Loading"><br>
从车的图片和非车的图片固定的地方取两个像素，将其值画在坐标轴上，多次之后可以得到下图左。然而一张图片像素太多了，都以这种方式比较无从计算。<br>
<img src="/img/note_ml_coursera_nn_computervision_3.png" alt="Image Loading"></p>
<h3 id="neurons-and-the-brain"><a class="markdownIt-Anchor" href="#neurons-and-the-brain"></a> Neurons and the brain</h3>
<p><strong>Neural Networks</strong><br>
Origins: Algorithms that try to mimic the brain.<br>
Was very widely used in 80s and early 90s; popularity diminished in late 90s.<br>
Recent resurgence: State-of-the-art technique for many applications.<br>
现在又火起来是因为计算机的计算能力提高了。</p>
<p><strong>The “one learning algorithm” hypothesis</strong><br>
如果切断耳朵与Auditory Cortex之间的神经，把通往眼睛的接上，听觉中枢会学会看。同样，切断手与Somatosensory Cortex之间的神经，把通往眼睛的接上，触觉中枢也会学会看。</p>
<p><strong>Sensor representations in the brain</strong><br>
<img src="/img/note_ml_coursera_sensor_representations_in_the_brain.png" alt="Image Loading"></p>
<h3 id="model-representation-2"><a class="markdownIt-Anchor" href="#model-representation-2"></a> Model representation</h3>
<p><strong>Neuron in the brain</strong><br>
<img src="/img/note_ml_coursera_neuron_in_the_brain1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_neuron_in_the_brain2.png" alt="Image Loading"></p>
<p><strong>Neuron model: Logistic unit</strong><br>
<img src="/img/note_ml_coursera_neuron_model_logistic_unit.png" alt="Image Loading"><br>
bias unit / input / output / weights = parameters</p>
<p><strong>Neural Network</strong><br>
<img src="/img/note_ml_coursera_neural_network.png" alt="Image Loading"><br>
input layer / hidden layer / output layer<br>
<img src="/img/note_ml_coursera_neural_network_formula.png" alt="Image Loading"></p>
<p><strong>Forward propagation: Vectorized implementation</strong><br>
<img src="/img/note_ml_coursera_forward_propagation_vectorized_implementation.png" alt="Image Loading"></p>
<p><strong>Neural Network learning its own features</strong><br>
<img src="/img/note_ml_coursera_neural_network_learning_its_own_features.png" alt="Image Loading"></p>
<p>可以看出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi mathvariant="normal">Θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\Theta}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">Θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span>与Logistic Regression的很相似，</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>θ</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">h_{\theta}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">h</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span>，只是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span></span></span></span>不同。</p>
<p><strong>Other network architectures</strong><br>
<img src="/img/note_ml_coursera_other_network_architectures.png" alt="Image Loading"></p>
<h3 id="examples-and-intuitions"><a class="markdownIt-Anchor" href="#examples-and-intuitions"></a> Examples and intuitions</h3>
<p><strong>Non-linear classification example: XOR/XNOR</strong><br>
<img src="/img/note_ml_coursera_non_linear_classification_example_xor_xnor.png" alt="Image Loading"></p>
<p><strong>Simple example: AND</strong><br>
<img src="/img/note_ml_coursera_simple_example_AND.png" alt="Image Loading"></p>
<p><strong>Example: OR function</strong><br>
<img src="/img/note_ml_coursera_example_or_function.png" alt="Image Loading"></p>
<p><strong>Negation:</strong><br>
<img src="/img/note_ml_coursera_negation.png" alt="Image Loading"></p>
<p><strong>Putting it together: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mi>X</mi><mi>N</mi><mi>O</mi><mi>R</mi><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_1 XNOR x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></strong><br>
<img src="/img/note_ml_coursera_putting_it_together.png" alt="Image Loading"></p>
<p><strong>Neural Network intuition</strong><br>
<img src="/img/note_ml_coursera_neural_network_intuition.png" alt="Image Loading"></p>
<p><strong>Handwritten digit classification</strong><br>
<img src="/img/note_ml_coursera_handwriting_digit_classification.png" alt="Image Loading"></p>
<h3 id="multi-class-classification"><a class="markdownIt-Anchor" href="#multi-class-classification"></a> Multi-class classification</h3>
<p><strong>Multiple output units: One-vs-all</strong><br>
<img src="/img/note_ml_coursera_multiple_output_units_one_vs_all.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_multiple_output_units_one_vs_all1.png" alt="Image Loading"></p>
<hr>
<h2 id="neural-networks-learning"><a class="markdownIt-Anchor" href="#neural-networks-learning"></a> Neural Networks Learning</h2>
<h3 id="cost-function-4"><a class="markdownIt-Anchor" href="#cost-function-4"></a> Cost function</h3>
<p><strong>Neural Network (Clasification)</strong><br>
<img src="/img/note_ml_coursera_neural_network_classification.png" alt="Image Loading"></p>
<p><strong>Cost function</strong><br>
<img src="/img/note_ml_coursera_neural_network_cost_function.png" alt="Image Loading"></p>
<h3 id="backpropagation-algorithm"><a class="markdownIt-Anchor" href="#backpropagation-algorithm"></a> Backpropagation algorithm</h3>
<p><strong>Gradient computation</strong><br>
<img src="/img/note_ml_coursera_gradient_computation.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_gradient_computation1.png" alt="Image Loading"></p>
<p><strong>Gradient computation: Backpropagation algorithm</strong><br>
<img src="/img/note_ml_coursera_backpropagation_algorithm.png" alt="Image Loading"></p>
<p><strong>Backpropagation algorithm</strong><br>
<img src="/img/note_ml_coursera_backpropagation_algorithm1.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Δ</span></span></span></span>表示全部。</p>
<h3 id="backpropagation-intuition"><a class="markdownIt-Anchor" href="#backpropagation-intuition"></a> Backpropagation intuition</h3>
<p><strong>Forward Propagation</strong><br>
<img src="/img/note_ml_coursera_nn_forward_propagation.png" alt="Image Loading"></p>
<p><strong>What is backpropagation doing?</strong><br>
简化一下想一下。<br>
<img src="/img/note_ml_coursera_what_is_backpropagation_doing.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_what_is_backpropagation_doing1.png" alt="Image Loading"></p>
<h3 id="implementation-note-unrolling-parameters"><a class="markdownIt-Anchor" href="#implementation-note-unrolling-parameters"></a> Implementation note: Unrolling parameters</h3>
<p><strong>Advanced optimization</strong><br>
<img src="/img/note_ml_coursera_advanced_optimization.png" alt="Image Loading"></p>
<p><strong>Example</strong><br>
<img src="/img/note_ml_coursera_example.png" alt="Image Loading"></p>
<p><strong>Learning Algorithm</strong><br>
<img src="/img/note_ml_coursera_learning_algorithm.png" alt="Image Loading"></p>
<p>Matrix的好处：forward propagation和back propagation时更方便。<br>
Vector的好处：用advanced optimization algorithms时需要。</p>
<h3 id="gradient-checking"><a class="markdownIt-Anchor" href="#gradient-checking"></a> Gradient checking</h3>
<p>可以排除几乎所有可能bug。<br>
<strong>Numerical estimation of gradients</strong><br>
假设<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>是实数。<br>
<img src="/img/note_ml_coursera_numerical_estimation_of_gradients.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">ε</span></span></span></span>的取值也不能太小，运算上可能有numerical problem。通常用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow><mn>1</mn><mn>0</mn></mrow><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">{10}^{-4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">0</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord">−</span><span class="mord mathrm">4</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>。</p>
<p><strong>Parameter vector <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span></strong><br>
<img src="/img/note_ml_coursera_parameter_vector.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_parameter_vector_implement.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_gradient_checking.png" alt="Image Loading"></p>
<h3 id="random-initialization"><a class="markdownIt-Anchor" href="#random-initialization"></a> Random initialization</h3>
<p><strong>Initial value of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span></span></span></span></strong><br>
For gradient descent and advanced optimization method, need initial value for <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span></span></span></span>.<br>
<code>optTheta = fminunc(@costFunction, initialTheta, options)</code></p>
<p><strong>Zero initialization</strong><br>
<img src="/img/note_ml_coursera_zero_initialization.png" alt="Image Loading"><br>
不适用于neural network，会造成每一层里各值都相等，浪费了每层这许多节点。</p>
<p><strong>Random initialization: Symmetry breaking</strong><br>
<img src="/img/note_ml_coursera_random_initialization.png" alt="Image Loading"></p>
<h3 id="putting-it-together"><a class="markdownIt-Anchor" href="#putting-it-together"></a> Putting it together</h3>
<p><strong>Training a neural network</strong><br>
1.Pick a network architecture (connectivity pattern between neurons)<br>
<img src="/img/note_ml_coursera_nn_pick_network_arch.png" alt="Image Loading"><br>
2.Start Training.<br>
<img src="/img/note_ml_coursera_training_a_neural_network1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_training_a_neural_network2.png" alt="Image Loading"></p>
<h3 id="backpropagation-example-autonomous-driving"><a class="markdownIt-Anchor" href="#backpropagation-example-autonomous-driving"></a> Backpropagation example: Autonomous driving</h3>
<p>Dean Pomerleau<br>
左下角是汽车看到的视角。左上第一条是人类司机选择的方向steering direction，第二条是算法选择的方向。<br>
<img src="/img/note_ml_coursera_autonomous_driving.png" alt="Image Loading"></p>
<h2 id="advice-for-applying-machine-learning"><a class="markdownIt-Anchor" href="#advice-for-applying-machine-learning"></a> Advice for Applying Machine Learning</h2>
<h3 id="deciding-what-to-try-next"><a class="markdownIt-Anchor" href="#deciding-what-to-try-next"></a> Deciding what to try next</h3>
<p><strong>Debugging a learning algorithm:</strong><br>
<img src="/img/note_ml_coursera_debugging_a_learning_algorithm.png" alt="Image Loading"><br>
不能盲目尝试下面这些可行策略，应该实现一个Diagnostic。</p>
<p><strong>Machine learning diagnostic:</strong><br>
Diagnostic: A test that you can run to gain insight what is/isn’t working with a learning algorithm, and gain guidance as to how best to improve its performance.<br>
Diagnostics can take time to implement, but doing so can be a very good use of your time.</p>
<h3 id="evaluating-a-hypothesis"><a class="markdownIt-Anchor" href="#evaluating-a-hypothesis"></a> Evaluating a hypothesis</h3>
<p><strong>Evaluating your hypothesis</strong><br>
虽然training error很小，然而可能会overfitting。<br>
如果feature很多，又没法plot。此时将数据分成两部分，比例大约7/3，一部分作为Training Set，一部分作为Test Set。（从后面得知这并不是最好的做法，应该三分。）</p>
<p><strong>Training/testing procedure for linear regression</strong><br>
<img src="/img/note_ml_coursera_training_testing_procedure_for_linear_regression.png" alt="Image Loading"></p>
<p><strong>Training/testing procedure for logistic regression</strong><br>
<img src="/img/note_ml_coursera_training_testing_procedure_for_logistic_regression.png" alt="Image Loading"></p>
<h3 id="model-selection-and-trainingvalidationtest-sets"><a class="markdownIt-Anchor" href="#model-selection-and-trainingvalidationtest-sets"></a> Model selection and training/validation/test sets</h3>
<p><strong>Overfitting example</strong><br>
Once parameters <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>, …, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">4</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> were fit to some set of data (training set), the error of the parameters as measured on that data (the training error <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>J</mi><mo>(</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> is likely to be lower than the actual generalization error.</p>
<p><strong>Model selection</strong><br>
<img src="/img/note_ml_coursera_model_selection.png" alt="Image Loading"><br>
d = degree of polynomial<br>
对每种model进行训练，得到vector <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>，然后将其用于test data，得到J，看看哪种model中的J最小。这样的问题是d可能会对test data过拟合，所以得到的错误率过于乐观，并不是很好的做法。</p>
<p><strong>Evaluating your hypothesis</strong><br>
<img src="/img/note_ml_coursera_evaluating_your_hypothesis.png" alt="Image Loading"><br>
将数据分成三部分，比例大约6/2/2，分别为Training Set/Cross Validation Set/Test Set。<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>c</mi><mi>v</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m_{cv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">m</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">c</span><span class="mord mathit" style="margin-right:0.03588em;">v</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>表示number of cross validation examples.</p>
<p><strong>Training/validation/test error</strong><br>
<img src="/img/note_ml_coursera_train_validation_test.png" alt="Image Loading"></p>
<p><strong>Model selection</strong><br>
<img src="/img/note_ml_coursera_model_selection_better.png" alt="Image Loading"><br>
得到<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>后在cross validataion set上进行测试，计算J。取其中最小的d。<br>
然后再在test set上运行，计算错误率。</p>
<h3 id="diagnosing-bias-vs-variance"><a class="markdownIt-Anchor" href="#diagnosing-bias-vs-variance"></a> Diagnosing bias vs. variance</h3>
<p>不是underfitting就是overfitting。</p>
<p><strong>Bias/variance</strong><br>
<img src="/img/note_ml_coursera_bias_variance1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_bias_variance2.png" alt="Image Loading"><br>
随着d值变大，training error会越来越小，而cross validation error会有一个最小值，从underfitting到overfitting。</p>
<p><strong>Diagnosing bias vs. variance</strong><br>
<img src="/img/note_ml_coursera_diagnosing_bias_vs_variance.png" alt="Image Loading"><br>
看两者是都高还是一高一低区分under还是over。</p>
<h3 id="regularization-and-biasvariance"><a class="markdownIt-Anchor" href="#regularization-and-biasvariance"></a> Regularization and bias/variance</h3>
<p><strong>Linear regression with regularization</strong><br>
<img src="/img/note_ml_coursera_linear_regression_with_regularization.png" alt="Image Loading"></p>
<p><strong>Choosing the regularization parameter <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span></strong><br>
<img src="/img/note_ml_coursera_choosing_the_regularization_parameter_lambda.png" alt="Image Loading"><br>
还是分成三组。<br>
<img src="/img/note_ml_coursera_choosing_the_regularization_parameter_lambda1.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span>每次乘以2，计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>，在cross validation组测试计算J，选择最小J的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span>。然后用其在test set里计算test error。</p>
<p><strong>Bias/variance as a function of the regularization parameter <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span></strong><br>
<img src="/img/note_ml_coursera_bias_variance_as_a_function_of_the_regularization_parameter_lambda.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span>小的时候容易overfitting，大的时候容易underfitting。<br>
实际曲线会noisy一点。</p>
<h3 id="learning-curves"><a class="markdownIt-Anchor" href="#learning-curves"></a> Learning curves</h3>
<p><strong>Learning curves</strong><br>
<img src="/img/note_ml_coursera_learning_curves.png" alt="Image Loading"><br>
横轴m是training set size。J{train}会逐渐变大，J{cv}会越来越小，这样就对了。</p>
<p><strong>High bias</strong><br>
<img src="/img/note_ml_coursera_high_bias.png" alt="Image Loading"></p>
<p><strong>High variance</strong><br>
<img src="/img/note_ml_coursera_high_variance.png" alt="Image Loading"><br>
J{train}过小，J{cv}过大，中间有个大gap。并且持续变化，不会平稳。</p>
<h3 id="deciding-what-to-try-nextrevisited"><a class="markdownIt-Anchor" href="#deciding-what-to-try-nextrevisited"></a> Deciding what to try next(revisited)</h3>
<p><strong>Debugging a learning algorithm</strong></p>
<ul>
<li>Get more training examples - fixes high variance，有利于在learning curve中发现问题。</li>
<li>Try smaller sets of features - fixes high variance.</li>
<li>Try getting additional features - fixes high bias.</li>
<li>Try adding polynomial features - fixes high bias.</li>
<li>Try decreasing <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span> - fixes high bias.</li>
<li>Try increaing <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span> - fixes high variance.</li>
</ul>
<p><strong>Neural networks and overfitting</strong><br>
<img src="/img/note_ml_coursera_neural_networks_and_overfitting.png" alt="Image Loading"></p>
<h2 id="machine-learning-system-design"><a class="markdownIt-Anchor" href="#machine-learning-system-design"></a> Machine Learning System Design</h2>
<h3 id="prioritizing-what-to-work-on-spam-classification-example"><a class="markdownIt-Anchor" href="#prioritizing-what-to-work-on-spam-classification-example"></a> Prioritizing what to work on: Spam classification example</h3>
<p><strong>Building a spam classifier</strong><br>
Example.<br>
<img src="/img/note_ml_coursera_building_a_spam_classifier_example.png" alt="Image Loading"><br>
Supervised learning.<br>
<img src="/img/note_ml_coursera_building_a_spam_classifier_method.png" alt="Image Loading"><br>
How to spend your time to make it have low error?</p>
<ul>
<li>Collect lots of data. E.g. “honeypot” project.</li>
<li>Develop sophisticated features based on email routing information (from email header).</li>
<li>Develop sophisticated features for message body, e.g. should “discount” and “discounts” be treated as the same word? How about “deal” and “Dealer”? Features about punctuation?</li>
<li>Develop sophisticated algorithm to detect misspellings (e.g. m0rtgage, med1cine, w4tches.)</li>
</ul>
<h3 id="error-analysis"><a class="markdownIt-Anchor" href="#error-analysis"></a> Error analysis</h3>
<p><strong>Recommended approach</strong></p>
<ul>
<li>Start with a simple algorithm that you can implement quickly. Implement it and test it on your cross-validation data.</li>
<li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li>
<li>Error analysis: Manually examine the examples (in cross validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.</li>
</ul>
<p><strong>Error Analysis</strong><br>
<img src="/img/note_ml_coursera_error_analysis.png" alt="Image Loading"></p>
<p><strong>The importantance of numerical evaluation</strong><br>
Should discount/discounts/discouted/discounting be treated as the same word?<br>
Can use “stemming” software (E.g. “Porter stemmer”)<br>
universe/university (不好的情况。)</p>
<p>Error analysis may not be helpful for deciding if this is likely to improve performance. Only solution is to try it and see if it works.<br>
Need numerical evaluation (e.g., cross validation error) of algorithm’s performance with and without stemming.<br>
Without stemming: 5% error<br>
With stemming: 3% error<br>
Distinguish upper vs. lower case(Mom/mom): 3.2%</p>
<h3 id="error-metrics-for-skewed-classes"><a class="markdownIt-Anchor" href="#error-metrics-for-skewed-classes"></a> Error metrics for skewed classes</h3>
<p><strong>Cancer classification example</strong><br>
<img src="/img/note_ml_coursera_cancer_classification_example.png" alt="Image Loading"><br>
Logistic regression得到1%的错误率。而下面的代码之间全部都改成y=0没cancer反而错误率只有0.5%。<br>
这种两种情况出现比例相差极多的情况就叫skewed classes. More positive examples than negative examples.<br>
用数据衡量这种情况时要用到Precision/Recall。<br>
<strong>Precision/Recall</strong><br>
<img src="/img/note_ml_coursera_precision_recall.png" alt="Image Loading"><br>
这两值都是越高越好。</p>
<h3 id="trading-off-precision-and-recall"><a class="markdownIt-Anchor" href="#trading-off-precision-and-recall"></a> Trading off precision and recall</h3>
<p><strong>Trading off precision and recall</strong><br>
<img src="/img/note_ml_coursera_trading_off_precision_and_recall.png" alt="Image Loading"><br>
通过修改threshold来操纵precision和recall值来满足自己的要求。<br>
0.9对应第一种情况，0.3对应第二种情况。<br>
曲线可能有多种形状。</p>
<p><strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">F_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> Score (F score)</strong><br>
<img src="/img/note_ml_coursera_f1_score.png" alt="Image Loading"><br>
直接求平均不好。还如之前所有直接y=1的情况，recall会很高，影响结果判断。<br>
应该计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">F_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">F</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> Score。相当于将两者的权重都降低了，其中任何一个小，整体都小。</p>
<h3 id="data-for-machine-learning"><a class="markdownIt-Anchor" href="#data-for-machine-learning"></a> Data for machine learning</h3>
<p><strong>Designing a high accuracy learning system</strong><br>
<img src="/img/note_ml_coursera_designing_a_high_accuracy_learning_system.png" alt="Image Loading"><br>
看图得知数据很少时，算法表现差异很大；当数据很多时，它们都差不多了。</p>
<p><strong>Large data rationale</strong><br>
<img src="/img/note_ml_coursera_large_data_rationale.png" alt="Image Loading"><br>
检验上述结论，想想本图的couter example和useful test。<br>
<img src="/img/note_ml_coursera_large_data_rationale1.png" alt="Image Loading"><br>
参数多数据多，于是bias和variance都小，结果就是不错。</p>
<p>满足1.人类可以从此数据推断。2.有很多数据。这两点，基本可以确定会有一个好结果。</p>
<h2 id="support-vector-machines"><a class="markdownIt-Anchor" href="#support-vector-machines"></a> Support Vector Machines</h2>
<p>SVM</p>
<h3 id="optimization-objective"><a class="markdownIt-Anchor" href="#optimization-objective"></a> Optimization objective</h3>
<p><strong>Alternative view of logistic regression</strong><br>
<img src="/img/note_ml_coursera_alternative_view_of_logistic_regression1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_alternative_view_of_logistic_regression2.png" alt="Image Loading"><br>
原来的曲线变成多段折线。x轴是z，y轴是cost。</p>
<p><strong>Support vector machine</strong><br>
<img src="/img/note_ml_coursera_logistic_regression.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_support_vector_machine.png" alt="Cost Function"><br>
C可以认为是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>λ</mi></mrow><annotation encoding="application/x-tex">1/\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="mord mathit">λ</span></span></span></span>。</p>
<p><strong>SVM hypothesis</strong><br>
<img src="/img/note_ml_coursera_svm_hypothesis.png" alt="Image Loading"></p>
<h3 id="large-margin-intuition"><a class="markdownIt-Anchor" href="#large-margin-intuition"></a> Large Margin Intuition</h3>
<p><strong>Support Vector Machine</strong><br>
<img src="/img/note_ml_coursera_support_vector_machine_revisited.png" alt="Image Loading"><br>
x轴是z，y轴是cost。</p>
<p><strong>SVM Decision Boundary</strong><br>
<img src="/img/note_ml_coursera_svm_decision_boundary.png" alt="Image Loading"><br>
当C特别大时，我们倾向于让框住的那一部分接近0.</p>
<p><strong>SVM Decision Boundary: Linearly separable case</strong><br>
<img src="/img/note_ml_coursera_svm_decision_boundary_linearly_separable_case.png" alt="Image Loading"><br>
The black decision boundary has a larger distance. That distance is called the margin of the support vector machine. Larger minimum distance from any of the training examples.</p>
<p><strong>Large margin classifier in presence of outliers</strong><br>
<img src="/img/note_ml_coursera_large_margin_classifiers_in_presence_of_outliers.png" alt="Image Loading"><br>
当有outliers时。如果C特别大，会是藕荷色那条线。如果C的值理智一点，就是黑色那条线。C的作用和之前的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">λ</span></span></span></span>差不多。</p>
<h3 id="the-mathematics-behind-large-margin-classification"><a class="markdownIt-Anchor" href="#the-mathematics-behind-large-margin-classification"></a> The mathematics behind large margin classification</h3>
<p><strong>Vector Inner Product</strong><br>
<img src="/img/note_ml_coursera_vector_inner_product.png" alt="Image Loading"></p>
<p><strong>SVM Decision Boundary</strong><br>
<img src="/img/note_ml_coursera_svm_decision_boundary_math.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_svm_decision_boundary_math1.png" alt="Image Loading"><br>
margin就是p。如果不假设<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>为0，绿线SVM Decision Boundary就是不过原点。</p>
<h3 id="kernals"><a class="markdownIt-Anchor" href="#kernals"></a> Kernals</h3>
<p><strong>Non-linear Decision Boundary</strong><br>
<img src="/img/note_ml_coursera_non_linear_decision_boundary.png" alt="Image Loading"></p>
<p><strong>Kernal</strong><br>
<img src="/img/note_ml_coursera_kernal.png" alt="Image Loading"><br>
Similarity Functions. Gaussian kernal.</p>
<p><strong>Kernals and Similarity</strong><br>
<img src="/img/note_ml_coursera_kernals_and_similarity.png" alt="Image Loading"></p>
<p><strong>Example</strong><br>
<img src="/img/note_ml_coursera_kernal_example.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_kernal_example1.png" alt="Image Loading"><br>
对于藕荷色的点，离l1近，所以f1约等于1；离其他点远，其他f都约等于0。<br>
对于青色的点，都远，所以f都约等于0。<br>
由于Theta3为0，所以boundary就是离l1和l2近的点，如图。</p>
<p><strong>Choosing the landmarks</strong><br>
<img src="/img/note_ml_coursera_choosing_the_landmarks.png" alt="Image Loading"><br>
l就是landmarks。就放在training examples上。</p>
<p><strong>SVM with Kernels</strong><br>
<img src="/img/note_ml_coursera_svm_with_kernels.png" alt="Image Loading"><br>
右边的f是feature vector。<br>
<img src="/img/note_ml_coursera_svm_with_kernels1.png" alt="Image Loading"></p>
<p><strong>SVM parameters</strong><br>
<img src="/img/note_ml_coursera_svm_parameters.png" alt="Image Loading"></p>
<h3 id="using-an-svm"><a class="markdownIt-Anchor" href="#using-an-svm"></a> Using an SVM</h3>
<p><img src="/img/note_ml_coursera_using_an_svm.png" alt="Image Loading"></p>
<p><strong>Kernel(similarity) functions:</strong><br>
<img src="/img/note_ml_coursera_kernel_functions.png" alt="Image Loading"></p>
<p><strong>Other choices of kernel</strong><br>
<img src="/img/note_ml_coursera_other_choices_of_kernel.png" alt="Image Loading"></p>
<p><strong>Multi-class classification</strong><br>
<img src="/img/note_ml_coursera_multi_class_classification.png" alt="Image Loading"></p>
<p><strong>Logistic regression vs. SVMs</strong><br>
<img src="/img/note_ml_coursera_logistic_regression_vs_svms.png" alt="Image Loading"></p>
<h2 id="clustering"><a class="markdownIt-Anchor" href="#clustering"></a> Clustering</h2>
<p>从这里开始Unsupervised.</p>
<h3 id="unsupervised-learning-introduction"><a class="markdownIt-Anchor" href="#unsupervised-learning-introduction"></a> Unsupervised learning introduction</h3>
<p><strong>Supervised learning</strong><br>
<img src="/img/note_ml_coursera_supervised_learning.png" alt="Image Loading"><br>
<strong>Unsupervised learning</strong><br>
<img src="/img/note_ml_coursera_unsupervised_learning.png" alt="Image Loading"><br>
区别是数据有没有label。让algorithm自己找特性。<br>
<strong>Applications of clustering</strong><br>
<img src="/img/note_ml_coursera_application_of_clustering.png" alt="Image Loading"><br>
一些clustering算法的应用示例。</p>
<h3 id="k-means-algorithm"><a class="markdownIt-Anchor" href="#k-means-algorithm"></a> K-means algorithm</h3>
<p><img src="/img/note_ml_coursera_k_means_example1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_k_means_example2.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_k_means_example3.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_k_means_example4.png" alt="Image Loading"><br>
K Means算法是一个重复迭代的算法：</p>
<ol>
<li>cluster assignment step. 将所有点根据所离最近的centroid分组。(最初的centroid是随机的。)</li>
<li>move centroid step.将centroid放到自己所在组的中心点。</li>
<li>重复上述两步，直到稳定。</li>
</ol>
<p><strong>K-means algorithm</strong><br>
<img src="/img/note_ml_coursera_k_means_algorithm_input.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_k_means_algorithm.png" alt="Image Loading"></p>
<p><strong>K-means for non-separated clusters</strong><br>
<img src="/img/note_ml_coursera_k_means_for_non_separated_clusters.png" alt="Image Loading"></p>
<h3 id="optimization-objective-2"><a class="markdownIt-Anchor" href="#optimization-objective-2"></a> Optimization Objective</h3>
<p><strong>K-means optimization objective</strong><br>
好处是检查是否正常工作和找到更加cluster和避开local optima。<br>
<img src="/img/note_ml_coursera_k_means_optimization_objective.png" alt="Image Loading"><br>
K-means算法的两步就相当于：先固定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">μ</span></span></span></span>最小化C，再固定C最小化<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">μ</span></span></span></span>。</p>
<h3 id="random-initialization-2"><a class="markdownIt-Anchor" href="#random-initialization-2"></a> Random initialization</h3>
<p><strong>Random initialization</strong><br>
Should have K &lt; m.<br>
Randomly pick K training examples.<br>
Set <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>μ</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mrow><mi>μ</mi></mrow><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">{\mu}_1,...,{\mu}_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit">μ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit">μ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> equal to these K examples.<br>
可能效果很好也可能很差。<br>
<img src="/img/note_ml_coursera_random_initialization_k_means.png" alt="Image Loading"><br>
可能会出现Local optima。<br>
<img src="/img/note_ml_coursera_local_optima.png" alt="Image Loading"><br>
所以应该运行K-means很多次。<br>
<img src="/img/note_ml_coursera_random_initialization_k_means_func.png" alt="Image Loading"></p>
<h3 id="choosing-the-number-of-clusters"><a class="markdownIt-Anchor" href="#choosing-the-number-of-clusters"></a> Choosing the number of clusters</h3>
<p>最常用的还是手动，比如看图。</p>
<p>一种方法叫做Elbow method:<br>
用不同的K跑很多遍，计算J，看图，找胳膊肘。有时这个胳膊肘并不明显，如右图。<br>
<img src="/img/note_ml_coursera_choosing_the_value_of_k_elbow_method.png" alt="Image Loading"></p>
<p>或者K-means的结果之后给别人用，那么就根据之后别人的表现来判断K。<br>
Sometimes, you’re running K-means to get clusters to use for some later/downstream purpose. Evaluate K-means based on a metric for how well it performs for that later porpose.<br>
<img src="/img/note_ml_coursera_choosing_the_value_of_k_downstream_performance.png" alt="Image Loading"></p>
<h2 id="dimensionality-reduction"><a class="markdownIt-Anchor" href="#dimensionality-reduction"></a> Dimensionality Reduction</h2>
<h3 id="motivation-i-data-compression"><a class="markdownIt-Anchor" href="#motivation-i-data-compression"></a> Motivation I: Data Compression</h3>
<p><img src="/img/note_ml_coursera_data_compression.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_data_compression1.png" alt="Image Loading"><br>
projection.</p>
<h3 id="motivation-ii-data-visualization"><a class="markdownIt-Anchor" href="#motivation-ii-data-visualization"></a> Motivation II: Data Visualization</h3>
<p><img src="/img/note_ml_coursera_data_visualization1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_data_visualization2.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_data_visualization3.png" alt="Image Loading"></p>
<h3 id="principal-component-analysis-problem-formulation"><a class="markdownIt-Anchor" href="#principal-component-analysis-problem-formulation"></a> Principal Component Analysis problem formulation</h3>
<p><strong>Principal Component Analysis(PCA) problem formulation</strong><br>
<img src="/img/note_ml_coursera_pca_problem_formulation.png" alt="Image Loading"><br>
projection error就是从原始位置到投射点的距离。<br>
<strong>PCA is not linear regression</strong><br>
<img src="/img/note_ml_coursera_pca_is_not_linear_regression.png" alt="Image Loading"><br>
linear regression试图缩小的是点与线之间y方向的距离，因为是要争取让x的表达式最接近y。<br>
PCA试图缩小的是点与线之间的垂直距离，没有y，所有x之间是平等的。</p>
<h3 id="principal-component-analysis-algorithm"><a class="markdownIt-Anchor" href="#principal-component-analysis-algorithm"></a> Principal Component Analysis algorithm</h3>
<p><strong>Data preprocessing</strong><br>
<img src="/img/note_ml_coursera_data_preprocessing.png" alt="Image Loading"><br>
<strong>Principal Component Analysis(PCA) algorithm</strong><br>
<img src="/img/note_ml_coursera_principal_component_analysis_algorithm.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_principal_component_analysis_algorithm1.png" alt="Image Loading"><br>
<strong>Principal Component Analysis(PCA) algorithm summary</strong><br>
<img src="/img/note_ml_coursera_pca_algorithm_summary.png" alt="Image Loading"></p>
<h3 id="reconstruction-from-compressed-representation"><a class="markdownIt-Anchor" href="#reconstruction-from-compressed-representation"></a> Reconstruction from compressed representation</h3>
<p><img src="/img/note_ml_coursera_reconstruction_from_compressed_representation.png" alt="Image Loading"></p>
<h3 id="choosing-the-number-of-principal-components"><a class="markdownIt-Anchor" href="#choosing-the-number-of-principal-components"></a> Choosing the Number of Principal Components</h3>
<p><img src="/img/note_ml_coursera_choosing_k1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_choosing_k2.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_choosing_k3.png" alt="Image Loading"></p>
<h3 id="advice-for-applying-pca"><a class="markdownIt-Anchor" href="#advice-for-applying-pca"></a> Advice for applying PCA</h3>
<p><strong>Supervised learning speedup</strong><br>
<img src="/img/note_ml_coursera_supervised_learning_speedup.png" alt="Image Loading"><br>
只在training data上运行PCA，计算出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>U</mi><mrow><mi>r</mi><mi>e</mi><mi>d</mi><mi>u</mi><mi>c</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">U_{reduce}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.10903em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">d</span><span class="mord mathit">u</span><span class="mord mathit">c</span><span class="mord mathit">e</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>后再应用于另两组。</p>
<p><strong>Application of PCA</strong><br>
Compression</p>
<ul>
<li>Reduce memory/disk needed to store data.</li>
<li>Speed up learning algorithm.</li>
</ul>
<p>Visualization</p>
<p><strong>Bad use of PCA: To prevent overfitting</strong><br>
<img src="/img/note_ml_coursera_bad_use_of_pca.png" alt="Image Loading"><br>
因为PCA还是会损失一些信息。</p>
<p><strong>PCA is sometimes used where it shouldn’t be</strong><br>
应该先用原始的进行计算，如果效果不好需要降维才用PCA。<br>
<img src="/img/note_ml_coursera_pca_is_sometimes_used_where_it_shouldn't_be.png" alt="Image Loading"></p>
<h2 id="anomaly-detection"><a class="markdownIt-Anchor" href="#anomaly-detection"></a> Anomaly Detection</h2>
<h3 id="problem-motivation"><a class="markdownIt-Anchor" href="#problem-motivation"></a> Problem motivation</h3>
<p><strong>Anomaly detection example</strong><br>
<img src="/img/note_ml_coursera_anomaly_detection_example.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_density_estimation.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_anomaly_detection_example1.png" alt="Image Loading"><br>
得到feature，建立model，用model计算test数据的数值，看看是否在正常范围内。</p>
<h3 id="gaussian-distribution"><a class="markdownIt-Anchor" href="#gaussian-distribution"></a> Gaussian distribution</h3>
<p><strong>Gaussian (Normal) distribution</strong><br>
<img src="/img/note_ml_coursera_gaussian_distribution.png" alt="Image Loading"></p>
<p><strong>Gaussian distribution example</strong><br>
<img src="/img/note_ml_coursera_gaussian_distribution_example.png" alt="Image Loading"><br>
阴影面积总为1。</p>
<p><strong>Parameter extimation</strong><br>
<img src="/img/note_ml_coursera_parameter_estimation.png" alt="Image Loading"><br>
看出数据是经过Gaussian Distribution生成的，计算<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit">μ</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">σ</span></span></span></span>。</p>
<h3 id="algorithm"><a class="markdownIt-Anchor" href="#algorithm"></a> Algorithm</h3>
<p><strong>Density estimation</strong><br>
<img src="/img/note_ml_coursera_density_estimation1.png" alt="Image Loading"></p>
<p><strong>Anomaly detection algorithm</strong><br>
<img src="/img/note_ml_coursera_anomaly_detection_algorithm.png" alt="Image Loading"></p>
<p><strong>Anomaly detection example</strong><br>
<img src="/img/note_ml_coursera_anomaly_detection_example2.png" alt="Image Loading"></p>
<h3 id="developing-and-evaluating-an-anomaly-detection-system"><a class="markdownIt-Anchor" href="#developing-and-evaluating-an-anomaly-detection-system"></a> Developing and evaluating an anomaly detection system</h3>
<p><strong>The importance of real-number evaluation</strong><br>
<img src="/img/note_ml_coursera_the_importance_of_real_number_evaluation.png" alt="Image Loading"></p>
<p><strong>Aircraft engines motivating example</strong><br>
<img src="/img/note_ml_coursera_aircraft_engines_motivating_example.png" alt="Image Loading"></p>
<p><strong>Algorithm evaluation</strong><br>
<img src="/img/note_ml_coursera_algorithm_evaluation.png" alt="Image Loading"></p>
<h3 id="anomaly-detection-vs-supervised-learning"><a class="markdownIt-Anchor" href="#anomaly-detection-vs-supervised-learning"></a> Anomaly detection vs. supervised learning</h3>
<p><img src="/img/note_ml_coursera_anomaly_detection_vs_supervised_learning1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_anomaly_detection_vs_supervised_learning2.png" alt="Image Loading"></p>
<h3 id="choosing-what-features-to-use"><a class="markdownIt-Anchor" href="#choosing-what-features-to-use"></a> Choosing what features to use</h3>
<p><strong>Non-gaussian features</strong><br>
<img src="/img/note_ml_coursera_non_gaussian_features.png" alt="Image Loading"><br>
看看直方图像不像Gaussian Distribution。像就可以用。如果不像的话就对数据做一些转换，让它像Gaussian。<br>
<img src="/img/note_ml_coursera_non_gaussian_features_example1.png" alt="Image Loading"></p>
<p><strong>Error analysis for anomaly detection</strong><br>
<img src="/img/note_ml_coursera_error_analysis_for_anomaly_detection.png" alt="Image Loading"><br>
针对这个问题，争取从数据中分析出一个新feature如x2。</p>
<p><strong>Monitoring computers in a data center</strong><br>
Choose features that might take on unusually large or small values in the event of an anomaly. 后两个在有错误时会很大，因为网络负载小时CPU还很忙，一定是有问题了。</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = memory use of computer</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = number of disk accesses/sec</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">x_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = CPU load</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">x_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">4</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = network traffic</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">x_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">5</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = CPU load / network traffic</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>6</mn></msub></mrow><annotation encoding="application/x-tex">x_6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">6</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = (CPU load)^2 / network traffic</li>
</ul>
<h3 id="multivariate-gaussian-distribution"><a class="markdownIt-Anchor" href="#multivariate-gaussian-distribution"></a> Multivariate Gaussian distribution</h3>
<p><strong>Motivating example: Monitoring machines in a data center</strong><br>
<img src="/img/note_ml_coursera_motivating_example.png" alt="Image Loading"><br>
这种情况下，使用传统Gaussian，绿X本该有错，却还在正常范围内。</p>
<p><strong>Multivariate Gaussian(Normal) distributioin</strong><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_distribution.png" alt="Image Loading"><br>
Octave命令det(Sigma)。</p>
<p><strong>Multivariate Gaussian(Normal) examples</strong><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_examples1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_examples2.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_examples3.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_examples4.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_examples5.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_examples6.png" alt="Image Loading"></p>
<h3 id="anomaly-detection-using-the-multivariate-gaussian-distribution"><a class="markdownIt-Anchor" href="#anomaly-detection-using-the-multivariate-gaussian-distribution"></a> Anomaly detection using the multivariate Gaussian distribution</h3>
<p><strong>Multivariate Gaussian(Normal) distribution</strong><br>
<img src="/img/note_ml_coursera_multivariate_gaussian_distribution_formula.png" alt="Image Loading"></p>
<p><strong>Anomaly detectioin with the multivariate Gaussian</strong><br>
<img src="/img/note_ml_coursera_anomaly_detection_with_the_multivariate_gaussian.png" alt="Image Loading"></p>
<p><strong>Relationship to original model</strong><br>
<img src="/img/note_ml_coursera_relationship_to_original_model.png" alt="Image Loading"><br>
original model对应只有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Σ</span></span></span></span>主对角线有值的multivariate Gaussian。<br>
<img src="/img/note_ml_coursera_relationship_to_original_model1.png" alt="Image Loading"></p>
<h2 id="recommender-systems"><a class="markdownIt-Anchor" href="#recommender-systems"></a> Recommender Systems</h2>
<h3 id="problem-formulation"><a class="markdownIt-Anchor" href="#problem-formulation"></a> Problem formulation</h3>
<p><strong>Example: Predicting movie ratings</strong><br>
<img src="/img/note_ml_coursera_example_predicting_movie_ratings.png" alt="Image Loading"><br>
feature很重要。</p>
<h3 id="content-based-recommendations"><a class="markdownIt-Anchor" href="#content-based-recommendations"></a> Content-based recommendations</h3>
<p>之所以叫这个名字是因为我们知道features of the content，比如movie有多romance多action。<br>
<strong>Content-based recommender systems</strong><br>
<img src="/img/note_ml_coursera_content_based_recommender_systems.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>u</mi></msub></mrow><annotation encoding="application/x-tex">n_u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">u</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>是User数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">n_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">m</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>是Movie数。按惯例添加feature之<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_0=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span></span>。下面的例子是预测Alice对Cute puppies of love的预测。</p>
<p><strong>Problem formulation</strong><br>
<img src="/img/note_ml_coursera_problem_formulation.png" alt="Image Loading"><br>
是一个linear regression problem.</p>
<p><strong>Optimization objective:</strong><br>
<img src="/img/note_ml_coursera_optimization_objective.png" alt="Image Loading"></p>
<p><strong>Optimization algorithm:</strong><br>
<img src="/img/note_ml_coursera_optimization_algorithm1.png" alt="Image Loading"></p>
<h3 id="collaborative-filtering"><a class="markdownIt-Anchor" href="#collaborative-filtering"></a> Collaborative filtering</h3>
<p>这种不需要知道features of content。它会feature learning。每个用户都让算法的表现更好一点，所以叫Collaborative。<br>
<strong>Problem motivation</strong><br>
<img src="/img/note_ml_coursera_problem_motivation.png" alt="Image Loading"><br>
每个用户告诉我们她们对各种电影的喜好，就是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mrow><mi>θ</mi></mrow><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">{\theta}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>都是0.</p>
<p><strong>Optimization algorithm</strong><br>
<img src="/img/note_ml_coursera_optimization_algorithm2.png" alt="Image Loading"></p>
<p><strong>Collaborative filtering</strong><br>
<img src="/img/note_ml_coursera_collaborative_filtering.png" alt="Image Loading"></p>
<h3 id="collaborative-filtering-algorithm"><a class="markdownIt-Anchor" href="#collaborative-filtering-algorithm"></a> Collaborative filtering algorithm</h3>
<p><strong>Collaborative filtering optimization objective</strong><br>
<img src="/img/note_ml_coursera_collaborative_filtering_optimization_objective.png" alt="Image Loading"></p>
<p><strong>Collaborative filtering algorithm</strong><br>
<img src="/img/note_ml_coursera_collaborative_filtering_algorithm.png" alt="Image Loading"></p>
<h3 id="vectorization-low-rank-matrix-factorization"><a class="markdownIt-Anchor" href="#vectorization-low-rank-matrix-factorization"></a> Vectorization: Low rank matrix factorization</h3>
<p><img src="/img/note_ml_coursera_collaborative_filtering1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_collaborative_filtering2.png" alt="Image Loading"></p>
<h3 id="finding-related-movies"><a class="markdownIt-Anchor" href="#finding-related-movies"></a> Finding related movies</h3>
<p><img src="/img/note_ml_coursera_finding_related_movies.png" alt="Image Loading"></p>
<h3 id="implementational-detail-mean-normalization"><a class="markdownIt-Anchor" href="#implementational-detail-mean-normalization"></a> Implementational detail: Mean normalization</h3>
<p><strong>Users who have not rated any movies</strong><br>
<img src="/img/note_ml_coursera_users_who_have_not_rated_any_movies.png" alt="Image Loading"><br>
只有最后一部分会起效果，而对其最小化，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>$就全是0，预测也就全是0。这样就不是太好。可以推荐一些平均值评价高的，使用mean normalization。</p>
<p><strong>Mean Normalization:</strong><br>
<img src="/img/note_ml_coursera_mean_normalization.png" alt="Image Loading"></p>
<h2 id="large-scale-machine-learning"><a class="markdownIt-Anchor" href="#large-scale-machine-learning"></a> Large Scale Machine Learning</h2>
<h3 id="learning-with-large-datasets"><a class="markdownIt-Anchor" href="#learning-with-large-datasets"></a> Learning with large datasets</h3>
<p><strong>Machine learning and data</strong><br>
之前见过这个例子。It’s not who has the best algorithm that wins. It’s who has the most data.</p>
<p><strong>Learning with large datasets</strong><br>
<img src="/img/note_ml_learning_with_large_datasets.png" alt="Image Loading"><br>
这样一步就要计算m次求和。</p>
<h3 id="stochastic-gradient-descent"><a class="markdownIt-Anchor" href="#stochastic-gradient-descent"></a> Stochastic gradient descent</h3>
<p><strong>Linear regression with gradient descent</strong><br>
<img src="/img/note_ml_coursera_linear_regression_with_gradient_descent.png" alt="Image Loading"><br>
复习一下。数据很大时，这种gradient descent被叫做Batch gradient descent。<br>
以linear regression为例，也适用于其他algorithms that are based on training gradient descent on a specific training set, like logistic regression, neural networks, etc.</p>
<p><img src="/img/note_ml_coursera_batch_vs_stochastic_gradient_descent.png" alt="Image Loading"><br>
不再求和。随机排序，每次就看一个example。</p>
<p><strong>Stochastic gradient descnet</strong><br>
<img src="/img/note_ml_coursera_stochastic_gradient_descent.png" alt="Image Loading"></p>
<h3 id="mini-batch-gradient-descent"><a class="markdownIt-Anchor" href="#mini-batch-gradient-descent"></a> Mini-batch gradient descent</h3>
<p><strong>Mini-batch gradient descent</strong><br>
Batch gradient descent: Use all m examples in each iteration.<br>
Stochastic gradient descent: Use 1 example in each iteration.<br>
Mini-batch gradient descent: Use b examples in each iteration.<br>
<img src="/img/note_ml_coursera_mini_batch_gradient_descent.png" alt="Image Loading"></p>
<h3 id="stochastic-gradient-descent-convergence"><a class="markdownIt-Anchor" href="#stochastic-gradient-descent-convergence"></a> Stochastic gradient descent convergence</h3>
<p><strong>Checking for convergence</strong><br>
<img src="/img/note_ml_coursera_checking_for_convergence1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_checking_for_convergence2.png" alt="Image Loading"><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>小一点，抖动会小一点，曲线更平滑。<br>
如果每5000而不是每1000画一次，曲线更平滑。<br>
如果cost曲线在上升，使用小一点的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>。</p>
<p><strong>Stochastic gradient descent</strong><br>
<img src="/img/note_ml_coursera_stochastic_gradient_descent1.png" alt="Image Loading"></p>
<h3 id="online-learning"><a class="markdownIt-Anchor" href="#online-learning"></a> Online learning</h3>
<p><strong>Online learning</strong><br>
<img src="/img/note_ml_coursera_online_learning.png" alt="Image Loading"><br>
x是起始位置、我们开的价格等feature。y是1或0表示顾客是否使用我们的shipping service。每次只看一个顾客。</p>
<p><strong>Other online learning example:</strong><br>
<img src="/img/note_ml_coursera_other_online_learning_example.png" alt="Image Loading"></p>
<h3 id="map-reduce-and-data-parallelism"><a class="markdownIt-Anchor" href="#map-reduce-and-data-parallelism"></a> Map-reduce and data parallelism</h3>
<p><strong>Map-reduce</strong><br>
<img src="/img/note_ml_coursera_map_reduce1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_map_reduce2.png" alt="Image Loading"></p>
<p><strong>Map-reduce and summation over the training set</strong><br>
<img src="/img/note_ml_coursera_map_reduce_and_summation_over_the_trainint_set.png" alt="Image Loading"></p>
<p><strong>Multi-core machines</strong><br>
<img src="/img/note_ml_coursera_multi_core_machines.png" alt="Image Loading"></p>
<h2 id="application-example-photo-ocr"><a class="markdownIt-Anchor" href="#application-example-photo-ocr"></a> Application Example Photo OCR</h2>
<h3 id="problem-description-and-pipeline"><a class="markdownIt-Anchor" href="#problem-description-and-pipeline"></a> Problem description and pipeline</h3>
<p><strong>The Photo OCR problem</strong><br>
<img src="/img/note_ml_coursera_the_photo_ocr_problem.png" alt="Image Loading"><br>
Photo Optical Character Recognition.</p>
<p><strong>Photo OCR pipeline</strong><br>
<img src="/img/note_ml_coursera_photo_ocr_pipeline.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_photo_ocr_pipeline1.png" alt="Image Loading"><br>
每一个部分有1-5个engineer。</p>
<h3 id="sliding-windows"><a class="markdownIt-Anchor" href="#sliding-windows"></a> Sliding windows</h3>
<p><img src="/img/note_ml_coursera_text_pedestrian_detection.png" alt="Image Loading"><br>
因为图片中的文字区域aspect ratio可能不同，行人识别要比其容易一些。</p>
<p><strong>Supervised learning for pedestrian detection</strong><br>
<img src="/img/note_ml_coursera_supervised_learning_for_pedestrian_detection.png" alt="Image Loading"></p>
<p><strong>Sliding window detection</strong><br>
<img src="/img/note_ml_coursera_sliding_window_detection1.png" alt="Image Loading"><br>
定义一个window，然后一点点移动，寻找行人。移动的距离叫做step-size/stride。<br>
<img src="/img/note_ml_coursera_sliding_window_detection2.png" alt="Image Loading"><br>
逐渐用更大一点的window。这个window在处理时也会缩小为82*36.<br>
<img src="/img/note_ml_coursera_sliding_window_detection3.png" alt="Image Loading"><br>
直到找到所有行人。</p>
<p><strong>Text detection</strong><br>
<img src="/img/note_ml_coursera_text_detection1.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_text_detection2.png" alt="Image Loading"><br>
白色区域是算法认为的文字处，灰色是疑似处。然后进行expansion。去掉aspect radio不对劲的，比如垂直细长条。</p>
<p><strong>1D Sliding window for character segmentation</strong><br>
<img src="/img/note_ml_coursera_1d_sliding_window_for_character_segmentation.png" alt="Image Loading"><br>
图中间是否有一个空白patch。</p>
<h3 id="getting-lots-of-data-artificial-data-synthesis"><a class="markdownIt-Anchor" href="#getting-lots-of-data-artificial-data-synthesis"></a> Getting lots of data: Artificial data synthesis</h3>
<p><strong>Character recognition</strong><br>
<img src="/img/note_ml_coursera_character_recognition.png" alt="Image Loading"></p>
<p><strong>Artificial data synthesis for photo OCR</strong><br>
<img src="/img/note_ml_coursera_artificial_data_synthesis_for_photo_ocr.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_artificial_data_synthesis_for_photo_ocr1.png" alt="Image Loading"><br>
想要更多更多training set，找字体库，粘贴到随机背景上。这种方法是无中生有。</p>
<p><strong>Synthesizing data by introducing distortions</strong><br>
<img src="/img/note_ml_coursera_synthesizing_data_by_introducing_distortions.png" alt="Image Loading"><br>
将原有字体变形。这种方法是从小样本生产大样本。</p>
<p>或者声音的例子：<br>
<img src="/img/note_ml_coursera_synthesizing_data_by_introducing_distortions_speech_recognition.png" alt="Image Loading"></p>
<p><img src="/img/note_ml_coursera_synthesizing_data_by_introducing_distortions1.png" alt="Image Loading"></p>
<p><strong>Discussion on getting more data</strong><br>
<img src="/img/note_ml_coursera_discussion_on_getting_more_data.png" alt="Image Loading"></p>
<p>A sanity check with learning curves, that having more data would help. Ask yourself seriously: what it takes to get ten times much creative data as you currently have, and not always, but sometimes, you may be surprised by how easy that turns out to be.</p>
<h3 id="ceiling-analysis-what-part-of-the-pipeline-to-work-on-next"><a class="markdownIt-Anchor" href="#ceiling-analysis-what-part-of-the-pipeline-to-work-on-next"></a> Ceiling analysis: What part of the pipeline to work on next</h3>
<p>不要浪费时间，事先估算每阶段工作量，安排好时间。<br>
<strong>Estimating the errors due to each component(ceiling analysis)</strong><br>
<img src="/img/note_ml_coursera_estimating_the_errors_due_to_each_component.png" alt="Image Loading"><br>
除了待测定的阶段，手动给每一个之前的阶段正确答案，然后看看总体系统的accuracy如何，这样就大概知道每个阶段大概需要做多少工作。</p>
<p><strong>Another ceiling analysis example</strong><br>
<img src="/img/note_ml_coursera_another_ceiling_analysis_example.png" alt="Image Loading"><br>
<img src="/img/note_ml_coursera_another_ceiling_analysis_example1.png" alt="Image Loading"></p>
<h2 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h2>
<h3 id="summary-and-thank-you"><a class="markdownIt-Anchor" href="#summary-and-thank-you"></a> Summary and Thank you</h3>
<p><img src="/img/note_ml_coursera_summary_main_topics.png" alt="Image Loading"></p>
<hr>
<center><font size="5px">(¦3[▓▓]&nbsp;&nbsp;好开心!</font></center>
<p><img src="/img/note_ml_coursera_machine_learning_completed.png" alt="Image Loading"></p>

  </div>
</article>



        
    </div>
    
      <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/archives/">博文</a></li>
         
          <li><a href="/categories/">分类</a></li>
         
          <li><a href="/tags/">标签</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.</span> <span class="toc-text"> Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#welcome"><span class="toc-number">1.1.</span> <span class="toc-text"> Welcome</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#what-is-machine-learning"><span class="toc-number">1.2.</span> <span class="toc-text"> What is machine learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#supervised-learning"><span class="toc-number">1.3.</span> <span class="toc-text"> Supervised Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#unsupervised-learning"><span class="toc-number">1.4.</span> <span class="toc-text"> Unsupervised Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear-regression-with-one-variable"><span class="toc-number">2.</span> <span class="toc-text"> Linear Regression with One Variable</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#model-representation"><span class="toc-number">2.1.</span> <span class="toc-text"> Model representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function"><span class="toc-number">2.2.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-intuition"><span class="toc-number">2.3.</span> <span class="toc-text"> Cost function intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent"><span class="toc-number">2.4.</span> <span class="toc-text"> Gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-for-linear-regression"><span class="toc-number">2.5.</span> <span class="toc-text"> Gradient descent for linear regression</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#linear-regression-with-multiple-variables"><span class="toc-number">3.</span> <span class="toc-text"> Linear Regression with Multiple Variables</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#multiple-features"><span class="toc-number">3.1.</span> <span class="toc-text"> Multiple features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-for-multiple-variables"><span class="toc-number">3.2.</span> <span class="toc-text"> Gradient descent for multiple variables</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-in-practice-i-feature-scaling"><span class="toc-number">3.3.</span> <span class="toc-text"> Gradient descent in practice I: Feature Scaling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-descent-in-practice-ii-learning-rate"><span class="toc-number">3.4.</span> <span class="toc-text"> Gradient descent in practice II: Learning rate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#features-and-polynomial-regression"><span class="toc-number">3.5.</span> <span class="toc-text"> Features and polynomial regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#normal-equation"><span class="toc-number">3.6.</span> <span class="toc-text"> Normal equation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#normal-equation-and-non-invertibility"><span class="toc-number">3.7.</span> <span class="toc-text"> Normal equation and non-invertibility</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#logistic-regression"><span class="toc-number">4.</span> <span class="toc-text"> Logistic Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#classification"><span class="toc-number">4.1.</span> <span class="toc-text"> Classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hypothesis-representation"><span class="toc-number">4.2.</span> <span class="toc-text"> Hypothesis Representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#decision-boundary"><span class="toc-number">4.3.</span> <span class="toc-text"> Decision boundary</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-2"><span class="toc-number">4.4.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#simplified-cost-function-and-gradient-descent"><span class="toc-number">4.5.</span> <span class="toc-text"> Simplified cost function and gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#advanced-optimization"><span class="toc-number">4.6.</span> <span class="toc-text"> Advanced optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-class-classification-one-vs-all"><span class="toc-number">4.7.</span> <span class="toc-text"> Multi-class classification: One-vs-all</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#regularization"><span class="toc-number">5.</span> <span class="toc-text"> Regularization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#the-problem-of-overfitting"><span class="toc-number">5.1.</span> <span class="toc-text"> The problem of overfitting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-3"><span class="toc-number">5.2.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regularized-linear-regression"><span class="toc-number">5.3.</span> <span class="toc-text"> Regularized linear regression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regularized-logistic-regression"><span class="toc-number">5.4.</span> <span class="toc-text"> Regularized logistic regression</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#neural-networks-representation"><span class="toc-number">6.</span> <span class="toc-text"> Neural Networks Representation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#non-linear-hypotheses"><span class="toc-number">6.1.</span> <span class="toc-text"> Non-linear hypotheses</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#neurons-and-the-brain"><span class="toc-number">6.2.</span> <span class="toc-text"> Neurons and the brain</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-representation-2"><span class="toc-number">6.3.</span> <span class="toc-text"> Model representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#examples-and-intuitions"><span class="toc-number">6.4.</span> <span class="toc-text"> Examples and intuitions</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multi-class-classification"><span class="toc-number">6.5.</span> <span class="toc-text"> Multi-class classification</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#neural-networks-learning"><span class="toc-number">7.</span> <span class="toc-text"> Neural Networks Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cost-function-4"><span class="toc-number">7.1.</span> <span class="toc-text"> Cost function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backpropagation-algorithm"><span class="toc-number">7.2.</span> <span class="toc-text"> Backpropagation algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backpropagation-intuition"><span class="toc-number">7.3.</span> <span class="toc-text"> Backpropagation intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#implementation-note-unrolling-parameters"><span class="toc-number">7.4.</span> <span class="toc-text"> Implementation note: Unrolling parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gradient-checking"><span class="toc-number">7.5.</span> <span class="toc-text"> Gradient checking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#random-initialization"><span class="toc-number">7.6.</span> <span class="toc-text"> Random initialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#putting-it-together"><span class="toc-number">7.7.</span> <span class="toc-text"> Putting it together</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#backpropagation-example-autonomous-driving"><span class="toc-number">7.8.</span> <span class="toc-text"> Backpropagation example: Autonomous driving</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#advice-for-applying-machine-learning"><span class="toc-number">8.</span> <span class="toc-text"> Advice for Applying Machine Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#deciding-what-to-try-next"><span class="toc-number">8.1.</span> <span class="toc-text"> Deciding what to try next</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#evaluating-a-hypothesis"><span class="toc-number">8.2.</span> <span class="toc-text"> Evaluating a hypothesis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-selection-and-trainingvalidationtest-sets"><span class="toc-number">8.3.</span> <span class="toc-text"> Model selection and training/validation/test sets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#diagnosing-bias-vs-variance"><span class="toc-number">8.4.</span> <span class="toc-text"> Diagnosing bias vs. variance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regularization-and-biasvariance"><span class="toc-number">8.5.</span> <span class="toc-text"> Regularization and bias/variance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#learning-curves"><span class="toc-number">8.6.</span> <span class="toc-text"> Learning curves</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#deciding-what-to-try-nextrevisited"><span class="toc-number">8.7.</span> <span class="toc-text"> Deciding what to try next(revisited)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#machine-learning-system-design"><span class="toc-number">9.</span> <span class="toc-text"> Machine Learning System Design</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prioritizing-what-to-work-on-spam-classification-example"><span class="toc-number">9.1.</span> <span class="toc-text"> Prioritizing what to work on: Spam classification example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#error-analysis"><span class="toc-number">9.2.</span> <span class="toc-text"> Error analysis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#error-metrics-for-skewed-classes"><span class="toc-number">9.3.</span> <span class="toc-text"> Error metrics for skewed classes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#trading-off-precision-and-recall"><span class="toc-number">9.4.</span> <span class="toc-text"> Trading off precision and recall</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#data-for-machine-learning"><span class="toc-number">9.5.</span> <span class="toc-text"> Data for machine learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#support-vector-machines"><span class="toc-number">10.</span> <span class="toc-text"> Support Vector Machines</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#optimization-objective"><span class="toc-number">10.1.</span> <span class="toc-text"> Optimization objective</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#large-margin-intuition"><span class="toc-number">10.2.</span> <span class="toc-text"> Large Margin Intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#the-mathematics-behind-large-margin-classification"><span class="toc-number">10.3.</span> <span class="toc-text"> The mathematics behind large margin classification</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kernals"><span class="toc-number">10.4.</span> <span class="toc-text"> Kernals</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#using-an-svm"><span class="toc-number">10.5.</span> <span class="toc-text"> Using an SVM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#clustering"><span class="toc-number">11.</span> <span class="toc-text"> Clustering</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#unsupervised-learning-introduction"><span class="toc-number">11.1.</span> <span class="toc-text"> Unsupervised learning introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-means-algorithm"><span class="toc-number">11.2.</span> <span class="toc-text"> K-means algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimization-objective-2"><span class="toc-number">11.3.</span> <span class="toc-text"> Optimization Objective</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#random-initialization-2"><span class="toc-number">11.4.</span> <span class="toc-text"> Random initialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#choosing-the-number-of-clusters"><span class="toc-number">11.5.</span> <span class="toc-text"> Choosing the number of clusters</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dimensionality-reduction"><span class="toc-number">12.</span> <span class="toc-text"> Dimensionality Reduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation-i-data-compression"><span class="toc-number">12.1.</span> <span class="toc-text"> Motivation I: Data Compression</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#motivation-ii-data-visualization"><span class="toc-number">12.2.</span> <span class="toc-text"> Motivation II: Data Visualization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#principal-component-analysis-problem-formulation"><span class="toc-number">12.3.</span> <span class="toc-text"> Principal Component Analysis problem formulation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#principal-component-analysis-algorithm"><span class="toc-number">12.4.</span> <span class="toc-text"> Principal Component Analysis algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reconstruction-from-compressed-representation"><span class="toc-number">12.5.</span> <span class="toc-text"> Reconstruction from compressed representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#choosing-the-number-of-principal-components"><span class="toc-number">12.6.</span> <span class="toc-text"> Choosing the Number of Principal Components</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#advice-for-applying-pca"><span class="toc-number">12.7.</span> <span class="toc-text"> Advice for applying PCA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#anomaly-detection"><span class="toc-number">13.</span> <span class="toc-text"> Anomaly Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#problem-motivation"><span class="toc-number">13.1.</span> <span class="toc-text"> Problem motivation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gaussian-distribution"><span class="toc-number">13.2.</span> <span class="toc-text"> Gaussian distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#algorithm"><span class="toc-number">13.3.</span> <span class="toc-text"> Algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#developing-and-evaluating-an-anomaly-detection-system"><span class="toc-number">13.4.</span> <span class="toc-text"> Developing and evaluating an anomaly detection system</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#anomaly-detection-vs-supervised-learning"><span class="toc-number">13.5.</span> <span class="toc-text"> Anomaly detection vs. supervised learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#choosing-what-features-to-use"><span class="toc-number">13.6.</span> <span class="toc-text"> Choosing what features to use</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#multivariate-gaussian-distribution"><span class="toc-number">13.7.</span> <span class="toc-text"> Multivariate Gaussian distribution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#anomaly-detection-using-the-multivariate-gaussian-distribution"><span class="toc-number">13.8.</span> <span class="toc-text"> Anomaly detection using the multivariate Gaussian distribution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#recommender-systems"><span class="toc-number">14.</span> <span class="toc-text"> Recommender Systems</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#problem-formulation"><span class="toc-number">14.1.</span> <span class="toc-text"> Problem formulation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#content-based-recommendations"><span class="toc-number">14.2.</span> <span class="toc-text"> Content-based recommendations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#collaborative-filtering"><span class="toc-number">14.3.</span> <span class="toc-text"> Collaborative filtering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#collaborative-filtering-algorithm"><span class="toc-number">14.4.</span> <span class="toc-text"> Collaborative filtering algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vectorization-low-rank-matrix-factorization"><span class="toc-number">14.5.</span> <span class="toc-text"> Vectorization: Low rank matrix factorization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#finding-related-movies"><span class="toc-number">14.6.</span> <span class="toc-text"> Finding related movies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#implementational-detail-mean-normalization"><span class="toc-number">14.7.</span> <span class="toc-text"> Implementational detail: Mean normalization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#large-scale-machine-learning"><span class="toc-number">15.</span> <span class="toc-text"> Large Scale Machine Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#learning-with-large-datasets"><span class="toc-number">15.1.</span> <span class="toc-text"> Learning with large datasets</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descent"><span class="toc-number">15.2.</span> <span class="toc-text"> Stochastic gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mini-batch-gradient-descent"><span class="toc-number">15.3.</span> <span class="toc-text"> Mini-batch gradient descent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descent-convergence"><span class="toc-number">15.4.</span> <span class="toc-text"> Stochastic gradient descent convergence</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#online-learning"><span class="toc-number">15.5.</span> <span class="toc-text"> Online learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#map-reduce-and-data-parallelism"><span class="toc-number">15.6.</span> <span class="toc-text"> Map-reduce and data parallelism</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#application-example-photo-ocr"><span class="toc-number">16.</span> <span class="toc-text"> Application Example Photo OCR</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#problem-description-and-pipeline"><span class="toc-number">16.1.</span> <span class="toc-text"> Problem description and pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sliding-windows"><span class="toc-number">16.2.</span> <span class="toc-text"> Sliding windows</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#getting-lots-of-data-artificial-data-synthesis"><span class="toc-number">16.3.</span> <span class="toc-text"> Getting lots of data: Artificial data synthesis</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ceiling-analysis-what-part-of-the-pipeline-to-work-on-next"><span class="toc-number">16.4.</span> <span class="toc-text"> Ceiling analysis: What part of the pipeline to work on next</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#conclusion"><span class="toc-number">17.</span> <span class="toc-text"> Conclusion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#summary-and-thank-you"><span class="toc-number">17.1.</span> <span class="toc-text"> Summary and Thank you</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&text=Machine Learning 课程笔记"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&is_video=false&description=Machine Learning 课程笔记"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Machine Learning 课程笔记&body=Check out this article: http://conglang.github.io/2015/07/15/note-machine-learning-coursera/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&title=Machine Learning 课程笔记"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://conglang.github.io/2015/07/15/note-machine-learning-coursera/&name=Machine Learning 课程笔记&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

    
    <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 聪
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">首页</a></li>
         
          <li><a href="/archives/">博文</a></li>
         
          <li><a href="/categories/">分类</a></li>
         
          <li><a href="/tags/">标签</a></li>
         
          <li><a href="/search/">搜索</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

</body>

</html>

<!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

<!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-74786593-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

    <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?4e074986ce7bd4c6c94338ce1a49c4be";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

<!-- Disqus Comments -->



